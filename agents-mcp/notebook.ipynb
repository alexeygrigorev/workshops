{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4bccf7-6451-4ada-886f-cdde70417657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a0da8-f2c1-4992-b4b6-0f934e6ce2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383ff68e-bcca-4d92-8ddb-ae65e7a558d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69326914-83db-4b30-a783-0920c42de277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848bb9af-8949-4f28-8f59-c040b2431da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x21213471160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bccd086-9cee-4202-8ebc-cf830bccc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24af1aec-7a75-447f-b30d-d3b429ef3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_call(call):\n",
    "    args = json.loads(call.arguments)\n",
    "    f_name = call.name\n",
    "    f = globals()[f_name]\n",
    "    result = f(**args)\n",
    "    result_json = json.dumps(result, indent=2)\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": call.call_id,\n",
    "        \"output\": result_json,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b3dec-9e2a-43ff-a84b-e7c78c18439a",
   "metadata": {},
   "source": [
    "RAG - retrieval augmented generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f155f2-4f60-4609-83b9-c17c8db2d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "If you want to look up the answer, explain why before making the call. Use as many \n",
    "keywords from the user question as possible when making first requests.\n",
    "\n",
    "Make multiple searches. Try to expand your search by using new keywords based on the results you\n",
    "get from the search.\n",
    "\n",
    "At the end, make a clarifying question based on what you presented and ask if there are \n",
    "other areas that the user wants to explore.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f304558-c3c8-4fae-b953-24e69cc1a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I just discovered the course, can I join it now?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577fd1a3-4be6-4e4d-b499-96d15c0b1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0af0468-3f50-459b-a6cc-b54cb51c4e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFunctionToolCall(arguments='{\"query\":\"join course now\"}', call_id='call_duHlzss45sRbTtmqsn6mMqn0', name='search', type='function_call', id='fc_68b5b9578b7c8191b1d5818b4fcf7b2905a76010493c254f', status='completed')\n",
      "Yes, you can still join the course even if it has already started. You remain eligible to submit homeworks, but keep in mind that there are deadlines for turning in final projects. It's best not to leave everything to the last minute to ensure you meet those deadlines.\n",
      "\n",
      "The course officially starts on **15th Jan 2024 at 17:00**, and it's recommended to register before this date. If you're interested in participating, make sure to enroll as soon as possible.\n",
      "\n",
      "Would you like more information on how to register, or is there anything else specific about the course you want to explore?\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    response = openai_client.responses.create(\n",
    "        model='gpt-4o-mini',\n",
    "        input=chat_messages,\n",
    "        tools=[search_tool]\n",
    "    )\n",
    "    \n",
    "    chat_messages.extend(response.output)\n",
    "\n",
    "    has_function_calls = False\n",
    "    \n",
    "    for entry in response.output:\n",
    "        if entry.type == 'message':\n",
    "            print(entry.content[0].text)\n",
    "        if entry.type == 'function_call':\n",
    "            print(entry)\n",
    "            result = make_call(entry)\n",
    "            chat_messages.append(result)\n",
    "            has_function_calls = True\n",
    "\n",
    "    if has_function_calls == False:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79da53e-9989-4d4d-882f-70af122d4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.llm import OpenAIClient\n",
    "from toyaikit.tools import Tools\n",
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIResponsesRunner\n",
    "from toyaikit.chat.runners import DisplayingRunnerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941be8a3-41a8-4a89-97bc-337dbbbdfb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools = Tools()\n",
    "agent_tools.add_tool(search, search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d21bde-b754-4398-9190-59f87718a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface = IPythonChatInterface()\n",
    "\n",
    "runner = OpenAIResponsesRunner(\n",
    "    tools=agent_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=OpenAIClient()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "417760f9-0930-43b9-8633-004bee1720ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = DisplayingRunnerCallback(chat_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b508aea8-7c54-4983-a56f-048e46bb19a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"install kafka\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"install kafka\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_DU98BzlSdsYHEgH0BLdl0EJl', 'output': '[\\n  {\\n    \"text\": \"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\\\nfastavro: pip install fastavro\\\\nAbhirup Ghosh\\\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran \\\\u2018gradle shadowjar\\\\u2019, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Kafka- python videos have low audio and hard to follow up\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"For example, when running JsonConsumer.java, got:\\\\nConsuming form kafka started\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nOr when running JsonProducer.java, got:\\\\nException in thread \\\\\"main\\\\\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\\\nSolution:\\\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"installing Kafka guide\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"installing Kafka guide\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_h6M7grhkkASe20OnrBDNmmAx', 'output': '[\\n  {\\n    \"text\": \"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\\\nfastavro: pip install fastavro\\\\nAbhirup Ghosh\\\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"You can do most of the course without a cloud. Almost everything we use (excluding BigQuery) can be run locally. We won\\\\u2019t be able to provide guidelines for some things, but most of the materials are runnable without GCP.\\\\nFor everything in the course, there\\\\u2019s a local alternative. You could even do the whole course locally.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Environment - The GCP and other cloud providers are unavailable in some countries. Is it possible to provide a guide to installing a home lab?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Kafka- python videos have low audio and hard to follow up\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran \\\\u2018gradle shadowjar\\\\u2019, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To install Kafka, the steps typically involve the following:</p>\n",
       "<ol>\n",
       "<li><p><strong>Download Kafka</strong>:</p>\n",
       "<ul>\n",
       "<li>Kafka distributions can be downloaded from the <a href=\"https://kafka.apache.org/downloads\">Apache Kafka website</a>.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Extract the Files</strong>:</p>\n",
       "<ul>\n",
       "<li>Once you download the Kafka package, extract it to a desired location on your filesystem.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Start Zookeeper</strong>:</p>\n",
       "<ul>\n",
       "<li>Kafka uses Zookeeper for distributed coordination. You can start Zookeeper with the following command:<pre><code class=\"language-bash\">bin/zookeeper-server-start.sh config/zookeeper.properties\n",
       "</code></pre>\n",
       "</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Start Kafka Broker</strong>:</p>\n",
       "<ul>\n",
       "<li>After Zookeeper is running, open another terminal and start the Kafka server:<pre><code class=\"language-bash\">bin/kafka-server-start.sh config/server.properties\n",
       "</code></pre>\n",
       "</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Create a Topic</strong> (optional):</p>\n",
       "<ul>\n",
       "<li>You can create a Kafka topic using the following command:<pre><code class=\"language-bash\">bin/kafka-topics.sh --create --topic your_topic_name --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\n",
       "</code></pre>\n",
       "</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Install Kafka Clients</strong>:</p>\n",
       "<ul>\n",
       "<li>If you're using Python, for example, you may want to install the <code>confluent-kafka</code> library. This can be done using:<pre><code class=\"language-bash\">pip install confluent-kafka\n",
       "</code></pre>\n",
       "</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Running Kafka</strong>:</p>\n",
       "<ul>\n",
       "<li>Once Kafka is running, you can use command line tools to produce and consume messages for your topics.</li>\n",
       "</ul>\n",
       "</li>\n",
       "</ol>\n",
       "<p>It seems like some additional context regarding Python integration was found, which could be relevant if you're working in a Python environment. However, if you're looking for a specific setup or have any issues during the installation, please let me know!</p>\n",
       "<h3>Clarifying Question:</h3>\n",
       "<p>Are you looking for a specific installation setup, like on Windows, macOS, or using Docker, or do you have a particular programming language in mind (like Java or Python)? Let me know if there's anything else specific you'd like to explore!</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = runner.loop(prompt='how do I install kafka', callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40664a79-aca8-44a3-9911-2f465eb7e25c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"install Kafka using Docker\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"install Kafka using Docker\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_PXNaOujU56hFYewWzxdP0NWv', 'output': '[\\n  {\\n    \"text\": \"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\\\nfastavro: pip install fastavro\\\\nAbhirup Ghosh\\\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran \\\\u2018gradle shadowjar\\\\u2019, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Kafka- python videos have low audio and hard to follow up\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"For example, when running JsonConsumer.java, got:\\\\nConsuming form kafka started\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nOr when running JsonProducer.java, got:\\\\nException in thread \\\\\"main\\\\\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\\\nSolution:\\\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)\",\\n    \"section\": \"Module 6: streaming with kafka\",\\n    \"question\": \"Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To install Kafka using Docker, you can follow these steps:</p>\n",
       "<ol>\n",
       "<li><p><strong>Install Docker</strong>: Ensure you have Docker installed on your machine. You can download it from the <a href=\"https://www.docker.com/get-started\">Docker website</a>.</p>\n",
       "</li>\n",
       "<li><p><strong>Use Docker Compose</strong>: Create a <code>docker-compose.yml</code> file to configure the Kafka and Zookeeper services. Here's a simple example:</p>\n",
       "<pre><code class=\"language-yaml\">version: '2'\n",
       "services:\n",
       "  zookeeper:\n",
       "    image: wurstmeister/zookeeper:3.4.6\n",
       "    ports:\n",
       "      - &quot;2181:2181&quot;\n",
       "  kafka:\n",
       "    image: wurstmeister/kafka:latest\n",
       "    ports:\n",
       "      - &quot;9092:9092&quot;\n",
       "    expose:\n",
       "      - &quot;9093&quot;\n",
       "    environment:\n",
       "      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092\n",
       "      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT\n",
       "      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092\n",
       "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Start the Services</strong>: Navigate to the directory where your <code>docker-compose.yml</code> file is located and run:</p>\n",
       "<pre><code class=\"language-bash\">docker-compose up -d\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Verify the Containers</strong>: Check that your Kafka and Zookeeper containers are running correctly with the command:</p>\n",
       "<pre><code class=\"language-bash\">docker ps\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Create a Topic</strong> (optional):</p>\n",
       "<ul>\n",
       "<li>You can create a topic using the following command after connecting to the Kafka container:</li>\n",
       "</ul>\n",
       "<pre><code class=\"language-bash\">docker exec -it &lt;kafka_container_name&gt; kafka-topics.sh --create --topic your_topic_name --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\n",
       "</code></pre>\n",
       "</li>\n",
       "</ol>\n",
       "<h3>Common Issues</h3>\n",
       "<ul>\n",
       "<li>If you encounter <code>kafka.errors.NoBrokersAvailable</code>, ensure your Kafka and Zookeeper containers are running and accessible. You can check their status with <code>docker ps</code>.</li>\n",
       "</ul>\n",
       "<p>This should give you a working Kafka setup using Docker. If you run into any specific issues while following these steps, feel free to ask!</p>\n",
       "<h3>Clarifying Question:</h3>\n",
       "<p>Do you need help with creating topics or producing/consuming messages once Kafka is up and running, or is there any other specific area you would like to explore related to Kafka in Docker?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_messages = runner.loop(\n",
    "    prompt='I want to use docker',\n",
    "    previous_messages=messages,\n",
    "    callback=callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5adfb94e-62b6-4729-a404-a666dd6e1c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: I just discovered the course, can I still join?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"join course late enrollment\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"join course late enrollment\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_tlHybx9ElxaPpf1S84kxCMLp', 'output': '[\\n  {\\n    \"text\": \"No, late submissions are not allowed. But if the form is still not closed and it\\\\u2019s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\\\nOlder news:[source1] [source2]\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Homework - Are late submissions of homework allowed?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, even if you don\\'t register, you\\'re still eligible to submit the homeworks.\\\\nBe aware, however, that there will be deadlines for turning in the final projects. So don\\'t leave everything for the last minute.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I still join the course after the start date?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"The purpose of this document is to capture frequently asked technical questions\\\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\\\u201cOffice Hours\\'\\' live.1\\\\nSubscribe to course public Google Calendar (it works from Desktop only).\\\\nRegister before the course starts using this link.\\\\nJoin the course Telegram channel with announcements.\\\\nDon\\\\u2019t forget to register in DataTalks.Club\\'s Slack and join the channel.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - When will the course start?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I follow the course after it finishes?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"No, you can only get a certificate if you finish the course with a \\\\u201clive\\\\u201d cohort. We don\\'t award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Certificate - Can I follow the course in a self-paced mode and get a certificate?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Yes, you can still join the course even after it has started. Despite not registering immediately, you are eligible to submit homework assignments, but be mindful of the deadlines for final projects to avoid any rush.</p>\n",
       "<p>Would you like to know more about specific course materials or upcoming deadlines? Is there anything else you'd like to explore regarding the course?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: deadlines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"course deadlines final project assign...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"course deadlines final project assignments\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_gb0fYzbH3CkD0Nl6GVYxEI6a', 'output': '[\\n  {\\n    \"text\": \"You can find the latest and up-to-date deadlines here: https://docs.google.com/spreadsheets/d/e/2PACX-1vQACMLuutV5rvXg5qICuJGL-yZqIV0FBD84CxPdC5eZHf8TfzB-CJT_3Mo7U7oGVTXmSihPgQxuuoku/pubhtml\\\\nAlso, take note of Announcements from @Au-Tomator for any extensions or other news. Or, the form may also show the updated deadline, if Instructor(s) has updated it.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Homework - What are homework and project deadlines?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, you can use any tool you want for your project.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Can I use Airflow instead for my final project?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Each submitted project will be evaluated by 3 (three) randomly assigned students that have also submitted the project.\\\\nYou will also be responsible for grading the projects from 3 fellow students yourself. Please be aware that: not complying to this rule also implies you failing to achieve the Certificate at the end of the course.\\\\nThe final grade you get will be the median score of the grades you get from the peer reviewers.\\\\nAnd of course, the peer review criteria for evaluating or being evaluated must follow the guidelines defined here.\",\\n    \"section\": \"Project\",\\n    \"question\": \"How is my capstone project going to be evaluated?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, even if you don\\'t register, you\\'re still eligible to submit the homeworks.\\\\nBe aware, however, that there will be deadlines for turning in the final projects. So don\\'t leave everything for the last minute.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I still join the course after the start date?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I follow the course after it finishes?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>You can find the latest and up-to-date deadlines for homework and projects at the following link: <a href=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQACMLuutV5rvXg5qICuJGL-yZqIV0FBD84CxPdC5eZHf8TfzB-CJT_3Mo7U7oGVTXmSihPgQxuuoku/pubhtml\">Course Deadlines</a>.</p>\n",
       "<p>Be sure to keep an eye on announcements from @Au-Tomator for any updates or extensions regarding deadlines.</p>\n",
       "<p>Is there anything specific about the deadlines or project submissions that you would like to know more about?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer',\n",
       "  'content': \"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nIf you want to look up the answer, explain why before making the call. Use as many \\nkeywords from the user question as possible when making first requests.\\n\\nMake multiple searches. Try to expand your search by using new keywords based on the results you\\nget from the search.\\n\\nAt the end, make a clarifying question based on what you presented and ask if there are \\nother areas that the user wants to explore.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'I just discovered the course, can I still join?'},\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"join course late enrollment\"}', call_id='call_tlHybx9ElxaPpf1S84kxCMLp', name='search', type='function_call', id='fc_68b5ba6f695881a38e33fa8f30fe56ff022431b5e643f207', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_tlHybx9ElxaPpf1S84kxCMLp',\n",
       "  'output': '[\\n  {\\n    \"text\": \"No, late submissions are not allowed. But if the form is still not closed and it\\\\u2019s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\\\nOlder news:[source1] [source2]\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Homework - Are late submissions of homework allowed?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, even if you don\\'t register, you\\'re still eligible to submit the homeworks.\\\\nBe aware, however, that there will be deadlines for turning in the final projects. So don\\'t leave everything for the last minute.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I still join the course after the start date?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"The purpose of this document is to capture frequently asked technical questions\\\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\\\u201cOffice Hours\\'\\' live.1\\\\nSubscribe to course public Google Calendar (it works from Desktop only).\\\\nRegister before the course starts using this link.\\\\nJoin the course Telegram channel with announcements.\\\\nDon\\\\u2019t forget to register in DataTalks.Club\\'s Slack and join the channel.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - When will the course start?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I follow the course after it finishes?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"No, you can only get a certificate if you finish the course with a \\\\u201clive\\\\u201d cohort. We don\\'t award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Certificate - Can I follow the course in a self-paced mode and get a certificate?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'},\n",
       " ResponseOutputMessage(id='msg_68b5ba7108b081a3ab16f600f7534a84022431b5e643f207', content=[ResponseOutputText(annotations=[], text=\"Yes, you can still join the course even after it has started. Despite not registering immediately, you are eligible to submit homework assignments, but be mindful of the deadlines for final projects to avoid any rush.\\n\\nWould you like to know more about specific course materials or upcoming deadlines? Is there anything else you'd like to explore regarding the course?\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message'),\n",
       " {'role': 'user', 'content': 'deadlines'},\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"course deadlines final project assignments\"}', call_id='call_gb0fYzbH3CkD0Nl6GVYxEI6a', name='search', type='function_call', id='fc_68b5ba773bc081a39951c8d36003b43d022431b5e643f207', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_gb0fYzbH3CkD0Nl6GVYxEI6a',\n",
       "  'output': '[\\n  {\\n    \"text\": \"You can find the latest and up-to-date deadlines here: https://docs.google.com/spreadsheets/d/e/2PACX-1vQACMLuutV5rvXg5qICuJGL-yZqIV0FBD84CxPdC5eZHf8TfzB-CJT_3Mo7U7oGVTXmSihPgQxuuoku/pubhtml\\\\nAlso, take note of Announcements from @Au-Tomator for any extensions or other news. Or, the form may also show the updated deadline, if Instructor(s) has updated it.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Homework - What are homework and project deadlines?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, you can use any tool you want for your project.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Can I use Airflow instead for my final project?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Each submitted project will be evaluated by 3 (three) randomly assigned students that have also submitted the project.\\\\nYou will also be responsible for grading the projects from 3 fellow students yourself. Please be aware that: not complying to this rule also implies you failing to achieve the Certificate at the end of the course.\\\\nThe final grade you get will be the median score of the grades you get from the peer reviewers.\\\\nAnd of course, the peer review criteria for evaluating or being evaluated must follow the guidelines defined here.\",\\n    \"section\": \"Project\",\\n    \"question\": \"How is my capstone project going to be evaluated?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, even if you don\\'t register, you\\'re still eligible to submit the homeworks.\\\\nBe aware, however, that there will be deadlines for turning in the final projects. So don\\'t leave everything for the last minute.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I still join the course after the start date?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I follow the course after it finishes?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'},\n",
       " ResponseOutputMessage(id='msg_68b5ba7870a481a38165bb0ae9d1b367022431b5e643f207', content=[ResponseOutputText(annotations=[], text='You can find the latest and up-to-date deadlines for homework and projects at the following link: [Course Deadlines](https://docs.google.com/spreadsheets/d/e/2PACX-1vQACMLuutV5rvXg5qICuJGL-yZqIV0FBD84CxPdC5eZHf8TfzB-CJT_3Mo7U7oGVTXmSihPgQxuuoku/pubhtml). \\n\\nBe sure to keep an eye on announcements from @Au-Tomator for any updates or extensions regarding deadlines. \\n\\nIs there anything specific about the deadlines or project submissions that you would like to know more about?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "932f1200-8f79-4753-a53e-44945b900926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "def search(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search the FAQ database for entries matching the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query text to look up in the course FAQ.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.\n",
    "    \"\"\"\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def add_entry(question: str, answer: str) -> None:\n",
    "    \"\"\"\n",
    "    Add a new entry to the FAQ database.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to be added to the FAQ database.\n",
    "        answer (str): The corresponding answer to the question.\n",
    "    \"\"\"\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc77ff35-a79d-4630-97bd-179d2c659913",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools = Tools()\n",
    "agent_tools.add_tool(search)\n",
    "agent_tools.add_tool(add_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79820f0c-3ece-496b-8636-7bfaaee8135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = OpenAIResponsesRunner(\n",
    "    tools=agent_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=OpenAIClient()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e59fbe9-c699-46a5-91e2-0e2fbf20b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: how do I do well in module 1?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"module 1 success tips\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"module 1 success tips\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_iMmVmrtf3g9U6YAtTp4LQill', 'output': '[\\n  {\\n    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\",\\n    \"section\": \"Module 5: pyspark\",\\n    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 322\\n  },\\n  {\\n    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\\\nexport PYTHONPATH=\\\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\\\u201d\\\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\\\"` appropriately.\\\\nAdditionally, you can check for the version of \\\\u2018py4j\\\\u2019 of the spark you\\\\u2019re using from here and update as mentioned above.\\\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\\n    \"section\": \"Module 5: pyspark\",\\n    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 323\\n  },\\n  {\\n    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\\n    \"section\": \"Module 4: analytics engineering with dbt\",\\n    \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 299\\n  },\\n  {\\n    \"text\": \"Issue:\\\\ne\\\\u2026\\\\nSolution:\\\\npip install psycopg2-binary\\\\nIf you already have it, you might need to update it:\\\\npip install psycopg2-binary --upgrade\\\\nOther methods, if the above fails:\\\\nif you are getting the \\\\u201c ModuleNotFoundError: No module named \\'psycopg2\\' \\\\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\\\nFirst uninstall the psycopg package\\\\nThen update conda or pip\\\\nThen install psycopg again using pip.\\\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\\n    \"section\": \"Module 1: Docker and Terraform\",\\n    \"question\": \"Postgres - ModuleNotFoundError: No module named \\'psycopg2\\'\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 112\\n  },\\n  {\\n    \"text\": \"create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \\\\\"TypeError: \\'module\\' object is not callable\\\\\"\\\\nSolution:\\\\nconn_string = \\\\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\\\"\\\\nengine = create_engine(conn_string)\",\\n    \"section\": \"Module 1: Docker and Terraform\",\\n    \"question\": \"Python - SQLALchemy - TypeError \\'module\\' object is not callable\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 124\\n  }\\n]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"module 1 strategies for success\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"module 1 strategies for success\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_2qWwIMe0NpaKjoaT4E9Lsw40', 'output': '[\\n  {\\n    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\",\\n    \"section\": \"Module 5: pyspark\",\\n    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 322\\n  },\\n  {\\n    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\\\nexport PYTHONPATH=\\\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\\\u201d\\\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\\\"` appropriately.\\\\nAdditionally, you can check for the version of \\\\u2018py4j\\\\u2019 of the spark you\\\\u2019re using from here and update as mentioned above.\\\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\\n    \"section\": \"Module 5: pyspark\",\\n    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 323\\n  },\\n  {\\n    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\\n    \"section\": \"Module 4: analytics engineering with dbt\",\\n    \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 299\\n  },\\n  {\\n    \"text\": \"Issue:\\\\ne\\\\u2026\\\\nSolution:\\\\npip install psycopg2-binary\\\\nIf you already have it, you might need to update it:\\\\npip install psycopg2-binary --upgrade\\\\nOther methods, if the above fails:\\\\nif you are getting the \\\\u201c ModuleNotFoundError: No module named \\'psycopg2\\' \\\\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\\\nFirst uninstall the psycopg package\\\\nThen update conda or pip\\\\nThen install psycopg again using pip.\\\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\\n    \"section\": \"Module 1: Docker and Terraform\",\\n    \"question\": \"Postgres - ModuleNotFoundError: No module named \\'psycopg2\\'\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 112\\n  },\\n  {\\n    \"text\": \"create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \\\\\"TypeError: \\'module\\' object is not callable\\\\\"\\\\nSolution:\\\\nconn_string = \\\\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\\\"\\\\nengine = create_engine(conn_string)\",\\n    \"section\": \"Module 1: Docker and Terraform\",\\n    \"question\": \"Python - SQLALchemy - TypeError \\'module\\' object is not callable\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 124\\n  }\\n]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To do well in Module 1 of your course, here are some key strategies derived from relevant information:</p>\n",
       "<ol>\n",
       "<li><p><strong>Understand Core Concepts</strong>: Familiarize yourself with the primary topics covered, especially related to Docker and Terraform, as the module focuses on these technologies.</p>\n",
       "</li>\n",
       "<li><p><strong>Practice Hands-On Coding</strong>: Make sure you actively work through coding exercises. For instance, you might face issues like a <code>ModuleNotFoundError</code> with packages such as <code>psycopg2</code>. Make sure you install necessary packages using commands like:</p>\n",
       "<pre><code class=\"language-bash\">pip install psycopg2-binary\n",
       "</code></pre>\n",
       "<p>If that fails, you may need to update or uninstall previous versions before reinstalling.</p>\n",
       "</li>\n",
       "<li><p><strong>Check Environment Variables</strong>: Understand how to properly set environment variables, especially for Python paths if you encounter import errors. The references suggest adding paths to your <code>PYTHONPATH</code> if you face issues with libraries.</p>\n",
       "</li>\n",
       "<li><p><strong>Utilize Documentation and Community Knowledge</strong>: Refer to course documentation and community forums for troubleshooting. Many errors you're likely to encounter have been previously discussed, and solutions are often shared by peers.</p>\n",
       "</li>\n",
       "<li><p><strong>Ask Questions</strong>: Engaging with your instructors and peers can provide clarity on complex topics and enhance your learning experience.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Would you like to delve deeper into any specific concept or area of Module 1? Or perhaps focus on troubleshooting common errors?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: add this back to FAQ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>add_entry({\"question\":\"How do I do well in Module 1?\",\"an...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"question\":\"How do I do well in Module 1?\",\"answer\":\"1. **Understand Core Concepts**: Familiarize yourself with the primary topics, especially related to Docker and Terraform.\\n\\n2. **Practice Hands-On Coding**: Work through coding exercises and install necessary packages like `psycopg2` using `pip install psycopg2-binary`. If you face errors, consider updating or uninstalling previous versions before reinstalling.\\n\\n3. **Check Environment Variables**: Learn to set environment variables correctly, especially for Python paths, to resolve import errors. For instance, you might need to edit your `PYTHONPATH`.\\n\\n4. **Utilize Documentation and Community Knowledge**: Refer to official course documentation and community forums for troubleshooting, as many errors are commonly discussed with shared solutions.\\n\\n5. **Ask Questions**: Engage with instructors and peers for clarity on complex topics.\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_s3p4w4Aj7029O0w651dmbjnb', 'output': 'null'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The information has been successfully added to the FAQ.</p>\n",
       "<p>If you have any other questions or need further assistance about the course or specific modules, feel free to ask!</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7736718-b83f-4a0a-803b-9a8fc63cf769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How do I do well in Module 1?',\n",
       " 'text': '1. **Understand Core Concepts**: Familiarize yourself with the primary topics, especially related to Docker and Terraform.\\n\\n2. **Practice Hands-On Coding**: Work through coding exercises and install necessary packages like `psycopg2` using `pip install psycopg2-binary`. If you face errors, consider updating or uninstalling previous versions before reinstalling.\\n\\n3. **Check Environment Variables**: Learn to set environment variables correctly, especially for Python paths, to resolve import errors. For instance, you might need to edit your `PYTHONPATH`.\\n\\n4. **Utilize Documentation and Community Knowledge**: Refer to official course documentation and community forums for troubleshooting, as many errors are commonly discussed with shared solutions.\\n\\n5. **Ask Questions**: Engage with instructors and peers for clarity on complex topics.',\n",
       " 'section': 'user added',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d297392b-8234-4f71-9549-164cf9bfdc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchTools:\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def search(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Search the FAQ database for entries matching the given query.\n",
    "    \n",
    "        Args:\n",
    "            query (str): Search query text to look up in the course FAQ.\n",
    "    \n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.\n",
    "        \"\"\"\n",
    "        boost = {'question': 3.0, 'section': 0.5}\n",
    "    \n",
    "        results = self.index.search(\n",
    "            query=query,\n",
    "            filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "            boost_dict=boost,\n",
    "            num_results=5,\n",
    "            output_ids=True\n",
    "        )\n",
    "    \n",
    "        return results\n",
    "\n",
    "    def add_entry(self, question: str, answer: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a new entry to the FAQ database.\n",
    "    \n",
    "        Args:\n",
    "            question (str): The question to be added to the FAQ database.\n",
    "            answer (str): The corresponding answer to the question.\n",
    "        \"\"\"\n",
    "        doc = {\n",
    "            'question': question,\n",
    "            'text': answer,\n",
    "            'section': 'user added',\n",
    "            'course': 'data-engineering-zoomcamp'\n",
    "        }\n",
    "        self.index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e67c665-a017-4c4b-a600-cab29bb93ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tools = SearchTools(index)\n",
    "\n",
    "agent_tools = Tools()\n",
    "agent_tools.add_tools(search_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6ac715b-82c0-4071-9982-a30cad4cf45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'add_entry',\n",
       "  'description': 'Add a new entry to the FAQ database.\\n\\nArgs:\\n    question (str): The question to be added to the FAQ database.\\n    answer (str): The corresponding answer to the question.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'question': {'type': 'string',\n",
       "     'description': 'question parameter'},\n",
       "    'answer': {'type': 'string', 'description': 'answer parameter'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'additionalProperties': False}},\n",
       " {'type': 'function',\n",
       "  'name': 'search',\n",
       "  'description': 'Search the FAQ database for entries matching the given query.\\n\\nArgs:\\n    query (str): Search query text to look up in the course FAQ.\\n\\nReturns:\\n    List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'query parameter'}},\n",
       "   'required': ['query'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ea38b71-fd58-4669-9459-93373993de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: howdy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "howdy\n"
     ]
    }
   ],
   "source": [
    "question = input('You:')\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf0a2d-3b3c-4781-8e89-8aef55fd62c1",
   "metadata": {},
   "source": [
    "## OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cea9e87-1f37-409e-840e-db5511eb27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0e46387-ce2c-44eb-81ec-357f41114635",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    function_tool(search_tools.search),\n",
    "    function_tool(search_tools.add_entry),\n",
    "    # add it here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e713d6a-27ba-4add-9456-405beeda97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.tools import wrap_instance_methods\n",
    "tools = wrap_instance_methods(function_tool, search_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25d04189-b126-46a6-a8fc-b1e2b439a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"faq_agent\",\n",
    "    instructions=developer_prompt,\n",
    "    tools=tools,\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a54e78e2-5857-4b50-9f0d-445cfe59220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat.runners import OpenAIAgentsSDKRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26ca649d-ce67-49e2-9000-f4de7b04fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = OpenAIAgentsSDKRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14c906cc-c091-45cc-9b38-109f40a902a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: how do I do well in module 1?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"how to do well in module 1\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"how to do well in module 1\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'question': 'How do I do well in Module 1?', 'text': '1. **Understand Core Concepts**: Familiarize yourself with the primary topics, especially related to Docker and Terraform.\\n\\n2. **Practice Hands-On Coding**: Work through coding exercises and install necessary packages like `psycopg2` using `pip install psycopg2-binary`. If you face errors, consider updating or uninstalling previous versions before reinstalling.\\n\\n3. **Check Environment Variables**: Learn to set environment variables correctly, especially for Python paths, to resolve import errors. For instance, you might need to edit your `PYTHONPATH`.\\n\\n4. **Utilize Documentation and Community Knowledge**: Refer to official course documentation and community forums for troubleshooting, as many errors are commonly discussed with shared solutions.\\n\\n5. **Ask Questions**: Engage with instructors and peers for clarity on complex topics.', 'section': 'user added', 'course': 'data-engineering-zoomcamp', '_id': 948}, {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Module Not Found Error in Jupyter Notebook .', 'course': 'data-engineering-zoomcamp', '_id': 322}, {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.', 'section': 'Module 5: pyspark', 'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp', '_id': 323}, {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", 'section': 'Module 1: Docker and Terraform', 'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", 'course': 'data-engineering-zoomcamp', '_id': 112}, {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp', '_id': 299}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To do well in Module 1, here are some effective strategies based on the information I found:</p>\n",
       "<ol>\n",
       "<li><p><strong>Understand Core Concepts</strong>: Focus on the primary topics related to Docker and Terraform. Make sure you grasp the foundational concepts thoroughly.</p>\n",
       "</li>\n",
       "<li><p><strong>Practice Hands-On Coding</strong>: Hands-on experience is crucial. Work through coding exercises and set up any necessary packages. For instance, ensure that you install <code>psycopg2</code> using the command:</p>\n",
       "<pre><code class=\"language-bash\">pip install psycopg2-binary\n",
       "</code></pre>\n",
       "<p>If you run into errors, consider uninstalling previous versions and reinstalling them.</p>\n",
       "</li>\n",
       "<li><p><strong>Check Environment Variables</strong>: Make sure you know how to set environment variables correctly. This is essential, especially for resolving any import errors in Python. Verify the <code>PYTHONPATH</code> is configured appropriately.</p>\n",
       "</li>\n",
       "<li><p><strong>Utilize Documentation and Community Knowledge</strong>: Engage with official course documentation and see if community forums have discussions on common errors. This can be incredibly helpful for troubleshooting.</p>\n",
       "</li>\n",
       "<li><p><strong>Ask Questions</strong>: Don't hesitate to reach out to instructors or peers if you need clarification on complex topics or concepts.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Would you like more details on any specific area, such as Docker, Terraform, or troubleshooting techniques? Or is there any other aspect of Module 1 you're interested in exploring further?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "await runner.run();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50040f30-c4b7-481e-bded-ced484706ee7",
   "metadata": {},
   "source": [
    "## Pydantic AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32355ba2-32eb-40fc-abe5-3c76b296dbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method SearchTools.search of <__main__.SearchTools object at 0x00000212148C6510>>,\n",
       " <bound method SearchTools.add_entry of <__main__.SearchTools object at 0x00000212148C6510>>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "tools = [\n",
    "    search_tools.search,\n",
    "    search_tools.add_entry\n",
    "]\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf9de5e3-477d-421f-a837-171173b05f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"faq_agent\",\n",
    "    instructions=developer_prompt,\n",
    "    tools=tools,\n",
    "    # model='gpt-4o-mini'\n",
    "    model='anthropic:claude-3-7-sonnet-latest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "746f4578-eeee-40d1-af16-f1627ae03bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat.runners import PydanticAIRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e00aa604-6746-4035-9616-99622acc5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = PydanticAIRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "349a0c26-6667-409a-aeb6-04bf63c72dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: how do I do well in module 1?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I'd be happy to help you with strategies for success in Module 1! Let me search the FAQ database for specific information about Module 1 and how to do well in it.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"module 1 success tips\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"module 1 success tips\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.', 'section': 'Module 5: pyspark', 'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp', '_id': 323}, {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp', '_id': 299}, {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Module Not Found Error in Jupyter Notebook .', 'course': 'data-engineering-zoomcamp', '_id': 322}, {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", 'section': 'Module 1: Docker and Terraform', 'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", 'course': 'data-engineering-zoomcamp', '_id': 112}, {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\", 'section': 'Module 1: Docker and Terraform', 'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\", 'course': 'data-engineering-zoomcamp', '_id': 125}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Let me search for more specific information about Module 1 success strategies:</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"module 1 docker terraform tips succe...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"module 1 docker terraform tips success\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g', 'course': 'data-engineering-zoomcamp', '_id': 150}, {'text': \"The error:\\nError: googleapi: Error 403: terraform-trans-campus@trans-campus-410115.iam.gserviceaccount.com does not have storage.buckets.create access to the Google Cloud project. Permission 'storage.buckets.create' denied on resource (or it may not exist)., forbidden\\nThe solution:\\nYou have to declare the project name as your Project ID, and not your Project name, available on GCP console Dashboard.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error creating Bucket: googleapi: Error 403: Permission denied to access ‘storage.buckets.create’', 'course': 'data-engineering-zoomcamp', '_id': 152}, {'text': 'It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later', 'course': 'data-engineering-zoomcamp', '_id': 142}, {'text': \"The issue was with the network. Google is not accessible in my country, I am using a VPN. And The terminal program does not automatically follow the system proxy and requires separate proxy configuration settings.I opened a Enhanced Mode in Clash, which is a VPN app, and 'terraform apply' works! So if you encounter the same issue, you can ask help for your vpn provider.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error:Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=coherent-ascent-379901\": oauth2: cannot fetch token: Post \"https://oauth2.googleapis.com/token\": dial tcp 172.217.163.42:443: i/o timeout', 'course': 'data-engineering-zoomcamp', '_id': 143}, {'text': 'When running\\nterraform apply\\non wsl2 I\\'ve got this error:\\n│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\\n│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\\nIT happens because there may be time desync on your machine which affects computing JWT\\nTo fix this, run the command\\nsudo hwclock -s\\nwhich fixes your system time.\\nReference', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.', 'course': 'data-engineering-zoomcamp', '_id': 146}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Let me search for specific advice on succeeding in Module 1:</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"tips for success module 1 data engin...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"tips for success module 1 data engineering\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv', 'section': 'Module 6: streaming with kafka', 'question': 'data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing', 'course': 'data-engineering-zoomcamp', '_id': 377}, {'text': 'Assuming you downloaded the Mage repo in the week 2 folder of the Data Engineering Zoomcamp, you might want to include your mage copy, demo pipelines and homework within your personal copy of the Data Engineering Zoomcamp repo. This will not work by default, because GitHub sees them as two separate repositories, and one does not track the other. To add the Mage files to your main DE Zoomcamp repo, you will need to:\\nMove the contents of the .gitignore file in your main .gitignore.\\nUse the terminal to cd into the Mage folder and:\\nrun “git remote remove origin” to de-couple the Mage repo,\\nrun “rm -rf .git” to delete local git files,\\nrun “git add .” to add the current folder as changes to stage, commit and push.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Git - How do I include the files in the Mage repo (including exercise files and homework) in a personal copy of the Data Engineering Zoomcamp repo?', 'course': 'data-engineering-zoomcamp', '_id': 191}, {'text': 'This error appeared when running the command: docker build -t taxi_ingest:v001 .\\nWhen feeding the database with the data the user id of the directory ny_taxi_postgres_data was changed to 999, so my user couldn’t access it when running the above command. Even though this is not the problem here it helped to raise the error due to the permission issue.\\nSince at this point we only need the files Dockerfile and ingest_data.py, to fix this error one can run the docker build command on a different directory (having only these two files).\\nA more complete explanation can be found here: https://stackoverflow.com/questions/41286028/docker-build-error-checking-context-cant-stat-c-users-username-appdata\\nYou can fix the problem by changing the permission of the directory on ubuntu with following command:\\nsudo chown -R $USER dir_path\\nOn windows follow the link: https://thegeekpage.com/take-ownership-of-a-file-folder-through-command-prompt-in-windows-10/ \\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAdded by\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKenan Arslanbay', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - build error: error checking context: 'can't stat '/home/user/repos/data-engineering/week_1_basics_n_setup/2_docker_sql/ny_taxi_postgres_data''.\", 'course': 'data-engineering-zoomcamp', '_id': 67}, {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?', 'course': 'data-engineering-zoomcamp', '_id': 3}, {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp', '_id': 299}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Let me search for information about assignments and homework for Module 1:</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"module 1 homework assignments\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"module 1 homework assignments\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Module Not Found Error in Jupyter Notebook .', 'course': 'data-engineering-zoomcamp', '_id': 322}, {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", 'section': 'Module 1: Docker and Terraform', 'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", 'course': 'data-engineering-zoomcamp', '_id': 112}, {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp', '_id': 299}, {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.', 'section': 'Module 5: pyspark', 'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp', '_id': 323}, {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)', 'section': 'Module 1: Docker and Terraform', 'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\", 'course': 'data-engineering-zoomcamp', '_id': 124}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Let me search for general success strategies for the course:</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"how to succeed in data engineering c...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"how to succeed in data engineering course\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'Assuming you downloaded the Mage repo in the week 2 folder of the Data Engineering Zoomcamp, you might want to include your mage copy, demo pipelines and homework within your personal copy of the Data Engineering Zoomcamp repo. This will not work by default, because GitHub sees them as two separate repositories, and one does not track the other. To add the Mage files to your main DE Zoomcamp repo, you will need to:\\nMove the contents of the .gitignore file in your main .gitignore.\\nUse the terminal to cd into the Mage folder and:\\nrun “git remote remove origin” to de-couple the Mage repo,\\nrun “rm -rf .git” to delete local git files,\\nrun “git add .” to add the current folder as changes to stage, commit and push.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Git - How do I include the files in the Mage repo (including exercise files and homework) in a personal copy of the Data Engineering Zoomcamp repo?', 'course': 'data-engineering-zoomcamp', '_id': 191}, {'text': 'Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv', 'section': 'Module 6: streaming with kafka', 'question': 'data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing', 'course': 'data-engineering-zoomcamp', '_id': 377}, {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?', 'course': 'data-engineering-zoomcamp', '_id': 3}, {'text': 'This error appeared when running the command: docker build -t taxi_ingest:v001 .\\nWhen feeding the database with the data the user id of the directory ny_taxi_postgres_data was changed to 999, so my user couldn’t access it when running the above command. Even though this is not the problem here it helped to raise the error due to the permission issue.\\nSince at this point we only need the files Dockerfile and ingest_data.py, to fix this error one can run the docker build command on a different directory (having only these two files).\\nA more complete explanation can be found here: https://stackoverflow.com/questions/41286028/docker-build-error-checking-context-cant-stat-c-users-username-appdata\\nYou can fix the problem by changing the permission of the directory on ubuntu with following command:\\nsudo chown -R $USER dir_path\\nOn windows follow the link: https://thegeekpage.com/take-ownership-of-a-file-folder-through-command-prompt-in-windows-10/ \\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAdded by\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKenan Arslanbay', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - build error: error checking context: 'can't stat '/home/user/repos/data-engineering/week_1_basics_n_setup/2_docker_sql/ny_taxi_postgres_data''.\", 'course': 'data-engineering-zoomcamp', '_id': 67}, {'text': 'All the main videos are stored in the Main “DATA ENGINEERING” playlist (no year specified). The Github repository has also been updated to show each video with a thumbnail, that would bring you directly to the same playlist below.\\nBelow is the MAIN PLAYLIST’. And then you refer to the year specific playlist for additional videos for that year like for office hours videos etc. Also find this playlist pinned to the slack channel.\\nh\\nttps://youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&si=NspQhtZhZQs1B9F-', 'section': 'General course-related questions', 'question': 'Course - Which playlist on YouTube should I refer to?', 'course': 'data-engineering-zoomcamp', '_id': 9}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Based on my searches, I'll compile the information about succeeding in Module 1 of the Data Engineering Zoomcamp. Although I didn't find specific success tips directly addressing Module 1, I can provide advice based on the course content and common issues students face.</p>\n",
       "<h1>How to Do Well in Module 1: Docker and Terraform</h1>\n",
       "<h2>Understanding the Module Content</h2>\n",
       "<p>Module 1 focuses on Docker and Terraform, which are foundational tools for data engineering. These technologies help you containerize applications and provision infrastructure.</p>\n",
       "<h2>Key Success Strategies:</h2>\n",
       "<h3>1. Set Up Your Environment Correctly</h3>\n",
       "<ul>\n",
       "<li>Install all required dependencies properly, including:<ul>\n",
       "<li>Docker and Docker Compose</li>\n",
       "<li>Python and necessary libraries (especially psycopg2 for PostgreSQL connections)</li>\n",
       "<li>Terraform for infrastructure provisioning</li>\n",
       "</ul>\n",
       "</li>\n",
       "</ul>\n",
       "<h3>2. Common Technical Issues to Watch For:</h3>\n",
       "<ul>\n",
       "<li>PostgreSQL connection issues: If you encounter &quot;ModuleNotFoundError: No module named 'psycopg2'&quot; when trying to connect to PostgreSQL, install psycopg2-binary with <code>pip install psycopg2-binary</code></li>\n",
       "<li>SQLAlchemy errors: Ensure you're using the correct connection string format</li>\n",
       "<li>Docker permissions issues: If you encounter errors with Docker build commands related to permissions, you may need to adjust directory permissions with <code>sudo chown -R $USER dir_path</code> on Linux</li>\n",
       "</ul>\n",
       "<h3>3. Terraform Best Practices:</h3>\n",
       "<ul>\n",
       "<li>Always run Terraform commands from the directory containing your .tf files</li>\n",
       "<li>When setting up GCP resources, use your Project ID (not Project name)</li>\n",
       "<li>Be aware of potential network/connectivity issues when using Terraform, especially if you're using a VPN</li>\n",
       "</ul>\n",
       "<h3>4. Follow Along with the Course Materials</h3>\n",
       "<ul>\n",
       "<li>Watch all the videos in the main playlist: https://youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb</li>\n",
       "<li>Complete all exercises as you go through the material</li>\n",
       "<li>The practical experience with Docker and Terraform is crucial for success</li>\n",
       "</ul>\n",
       "<h3>5. Homework Preparation</h3>\n",
       "<ul>\n",
       "<li>Make sure you understand how to:<ul>\n",
       "<li>Build and run Docker containers</li>\n",
       "<li>Use Docker Compose for multi-container applications</li>\n",
       "<li>Write and apply Terraform configurations</li>\n",
       "<li>Work with PostgreSQL databases in containerized environments</li>\n",
       "</ul>\n",
       "</li>\n",
       "</ul>\n",
       "<h3>6. Actively Participate</h3>\n",
       "<ul>\n",
       "<li>Join discussions in the course Slack channel</li>\n",
       "<li>Ask questions when you're stuck - many common issues have solutions in the FAQ</li>\n",
       "</ul>\n",
       "<h2>General Course Success Tips</h2>\n",
       "<ul>\n",
       "<li>Be consistent with your learning schedule</li>\n",
       "<li>Hands-on practice is more important than just watching videos</li>\n",
       "<li>Keep your GitHub repository organized and up-to-date</li>\n",
       "<li>Submit homework on time to get feedback</li>\n",
       "</ul>\n",
       "<p>Would you like me to elaborate on any specific aspect of Module 1? For example, would you like more details about Docker configuration, Terraform setup, or tips for the homework assignments?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "await runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f992d1-1f02-4cae-9c20-7d460fdbaf84",
   "metadata": {},
   "source": [
    "## MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9239d-8734-4540-adc8-053502c2aaa5",
   "metadata": {},
   "source": [
    "agent <-> MCP server <-> tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "664603bd-b21f-4aea-84d0-d1cc432db98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.mcp import MCPClient, SubprocessMCPTransport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c87b89cd-48c0-48d1-ad15-1663ad981165",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"uv run python main.py\".split()\n",
    "workdir = \"mcp_faq\"\n",
    "\n",
    "client = MCPClient(\n",
    "    transport=SubprocessMCPTransport(\n",
    "        server_command=command,\n",
    "        workdir=workdir\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7151143a-a6a3-4bae-8117-c5e61f128476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: uv run python main.py\n"
     ]
    }
   ],
   "source": [
    "client.start_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd7ead6b-8daa-49b9-a3c3-cdf4060a0338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.13.1'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'protocolVersion': '2024-11-05',\n",
       " 'capabilities': {'experimental': {},\n",
       "  'prompts': {'listChanged': False},\n",
       "  'resources': {'subscribe': False, 'listChanged': False},\n",
       "  'tools': {'listChanged': True}},\n",
       " 'serverInfo': {'name': 'Demo 🚀', 'version': '1.13.1'}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "247d5d44-c3b5-4372-8b9b-a09c8b463ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending initialized notification...\n",
      "Handshake completed successfully\n"
     ]
    }
   ],
   "source": [
    "client.initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b711b32f-cad2-40ea-958e-458d7be99db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving available tools...\n",
      "Available tools: ['add_entry', 'search']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'add_entry',\n",
       "  'description': 'Add a new entry to the FAQ database.\\n\\nArgs:\\n    question (str): The question to be added to the FAQ database.\\n    answer (str): The corresponding answer to the question.',\n",
       "  'inputSchema': {'properties': {'question': {'title': 'Question',\n",
       "     'type': 'string'},\n",
       "    'answer': {'title': 'Answer', 'type': 'string'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'type': 'object'},\n",
       "  '_meta': {'_fastmcp': {'tags': []}}},\n",
       " {'name': 'search',\n",
       "  'description': 'Search the FAQ database for entries matching the given query.\\n\\nArgs:\\n    query (str): Search query text to look up in the course FAQ.\\n\\nReturns:\\n    List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.',\n",
       "  'inputSchema': {'properties': {'query': {'title': 'Query',\n",
       "     'type': 'string'}},\n",
       "   'required': ['query'],\n",
       "   'type': 'object'},\n",
       "  'outputSchema': {'properties': {'result': {'items': {'additionalProperties': True,\n",
       "      'type': 'object'},\n",
       "     'title': 'Result',\n",
       "     'type': 'array'}},\n",
       "   'required': ['result'],\n",
       "   'title': '_WrappedResult',\n",
       "   'type': 'object',\n",
       "   'x-fastmcp-wrap-result': True},\n",
       "  '_meta': {'_fastmcp': {'tags': []}}}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7c94e49-c900-495a-aac1-080e6f6c62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'how do I run docker?'}\n"
     ]
    }
   ],
   "source": [
    "result = client.call_tool('search', {'query': 'how do I run docker?'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2bf9f6e-e946-4f97-95f2-0491a45f445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.mcp import MCPTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3113b060-d19f-44a7-9c2e-4ad10ea3d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_tools = MCPTools(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ce1397a-87c8-471a-8d39-626a5c1eec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = OpenAIResponsesRunner(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=OpenAIClient(model='gpt-4o-mini')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffeddb4e-86d3-4bad-81c0-60583acc10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: how do I insall kafka?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'install Kafka'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"install Kafka\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"install Kafka\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_Mvc7onXzmltK2P0RvjlXLT6X', 'output': '[{\"text\":\"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\\\nfastavro: pip install fastavro\\\\nAbhirup Ghosh\\\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Kafka- python videos have low audio and hard to follow up\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"For example, when running JsonConsumer.java, got:\\\\nConsuming form kafka started\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nOr when running JsonProducer.java, got:\\\\nException in thread \\\\\"main\\\\\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\\\nSolution:\\\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent\",\"course\":\"data-engineering-zoomcamp\"}]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'Kafka installation guide'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"Kafka installation guide\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"Kafka installation guide\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_PKPYFpvKlGEPPKSAgFgQe7j5', 'output': '[{\"text\":\"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Kafka- python videos have low audio and hard to follow up\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\\\nfastavro: pip install fastavro\\\\nAbhirup Ghosh\\\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"For example, when running JsonConsumer.java, got:\\\\nConsuming form kafka started\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nOr when running JsonProducer.java, got:\\\\nException in thread \\\\\"main\\\\\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\\\nSolution:\\\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent\",\"course\":\"data-engineering-zoomcamp\"}]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'how to set up Kafka on local machine'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"how to set up Kafka on local machine\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"how to set up Kafka on local machine\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_dRzpKUiD8SdLPTxOAnEGj6FL', 'output': '[{\"text\":\"You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\\\nYou might face some challenges, especially for Windows users. If you face cnd2\\\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\\\nUsing GitHub Codespaces\\\\nSetting up the environment on a cloudV Mcodespace\\\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.\",\"section\":\"General course-related questions\",\"question\":\"Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"How do I check compatibility of local and container Spark versions?\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Kafka- python videos have low audio and hard to follow up\",\"course\":\"data-engineering-zoomcamp\"}]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To install Apache Kafka, follow these general steps. Depending on your operating system, the process may vary slightly.</p>\n",
       "<h3>1. <strong>Download Kafka</strong></h3>\n",
       "<ul>\n",
       "<li>Go to the <a href=\"https://kafka.apache.org/downloads\">Apache Kafka download page</a>.</li>\n",
       "<li>Choose the latest version and download the binary files.</li>\n",
       "</ul>\n",
       "<h3>2. <strong>Extract the Files</strong></h3>\n",
       "<ul>\n",
       "<li>Unzip the downloaded file to a directory of your choice.</li>\n",
       "</ul>\n",
       "<h3>3. <strong>Install Java</strong></h3>\n",
       "<p>Kafka requires Java to run. Ensure that you have JDK installed and set the <code>JAVA_HOME</code> environment variable.</p>\n",
       "<h3>4. <strong>Start Zookeeper</strong></h3>\n",
       "<p>Kafka relies on Zookeeper, which is included in its download. Open a terminal and navigate to the Kafka directory. Run the command:</p>\n",
       "<pre><code class=\"language-bash\">bin/zookeeper-server-start.sh config/zookeeper.properties\n",
       "</code></pre>\n",
       "<h3>5. <strong>Start Kafka Server</strong></h3>\n",
       "<p>In a new terminal window, also in the Kafka directory, run:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-server-start.sh config/server.properties\n",
       "</code></pre>\n",
       "<h3>6. <strong>Create a Topic</strong></h3>\n",
       "<p>To create a topic named <code>test</code>, run:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\n",
       "</code></pre>\n",
       "<h3>7. <strong>Send Messages</strong></h3>\n",
       "<p>You can send messages to the newly created topic with:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-console-producer.sh --topic test --bootstrap-server localhost:9092\n",
       "</code></pre>\n",
       "<p>Just type messages and hit enter to send.</p>\n",
       "<h3>8. <strong>Consume Messages</strong></h3>\n",
       "<p>In another terminal, you can consume messages with:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-console-consumer.sh --topic test --from-beginning --bootstrap-server localhost:9092\n",
       "</code></pre>\n",
       "<h3>Additional Information:</h3>\n",
       "<ul>\n",
       "<li>If you're using <strong>Docker</strong>, you can set up a Kafka instance using Docker Compose.</li>\n",
       "<li>Ensure your firewall allows the ports used by Kafka (default is 9092).</li>\n",
       "</ul>\n",
       "<p>Would you like more details on any specific step or additional areas like Docker installation or configuration settings?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "20a8c370-1bb3-4bca-ac00-6bd4ef48fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.mcp import MCPServerSSE\n",
    "\n",
    "faq_mcp_client = MCPServerSSE(\n",
    "    url='http://localhost:8000/sse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4813cba-3638-44f0-87e3-c21fab4e6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"faq_agent\",\n",
    "    instructions=developer_prompt,\n",
    "    model='anthropic:claude-3-7-sonnet-latest',\n",
    "    toolsets=[faq_mcp_client]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6258195-e1fb-4fc1-ae20-d9d36496401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = PydanticAIRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17c73985-705e-41c0-aacf-d971b36a9b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: how do I install kafka for python\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I'll help you with installing Kafka for Python. Let me search for information about this topic in our FAQ database.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"install kafka python\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"install kafka python\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py', 'course': 'data-engineering-zoomcamp'}, {'text': 'tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\nKafka Python Videos - Rides.csv\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.', 'section': 'Module 6: streaming with kafka', 'question': 'Kafka- python videos have low audio and hard to follow up', 'course': 'data-engineering-zoomcamp'}, {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build', 'course': 'data-engineering-zoomcamp'}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp'}, {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent', 'course': 'data-engineering-zoomcamp'}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I see some information about Kafka for Python, but let's search for more specific installation instructions.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"python kafka client library installa...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"python kafka client library installation\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py', 'course': 'data-engineering-zoomcamp'}, {'text': 'tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\nKafka Python Videos - Rides.csv\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.', 'section': 'Module 6: streaming with kafka', 'question': 'Kafka- python videos have low audio and hard to follow up', 'course': 'data-engineering-zoomcamp'}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp'}, {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build', 'course': 'data-engineering-zoomcamp'}, {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent', 'course': 'data-engineering-zoomcamp'}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Let's try one more search to find additional Python Kafka client libraries:</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\": \"python kafka client libraries\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\": \"python kafka client libraries\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[{'text': 'tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\nKafka Python Videos - Rides.csv\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.', 'section': 'Module 6: streaming with kafka', 'question': 'Kafka- python videos have low audio and hard to follow up', 'course': 'data-engineering-zoomcamp'}, {'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py', 'course': 'data-engineering-zoomcamp'}, {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build', 'course': 'data-engineering-zoomcamp'}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp'}, {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent', 'course': 'data-engineering-zoomcamp'}]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Based on the search results, I can provide you with information on installing Kafka for Python. There are a few popular Python client libraries for Apache Kafka:</p>\n",
       "<h2>How to Install Kafka for Python</h2>\n",
       "<h3>1. Confluent Kafka Python Client (Recommended)</h3>\n",
       "<p>The Confluent Kafka Python client is one of the most widely used and well-maintained libraries:</p>\n",
       "<pre><code class=\"language-bash\"># Using pip\n",
       "pip install confluent-kafka\n",
       "\n",
       "# Using conda\n",
       "conda install conda-forge::python-confluent-kafka\n",
       "</code></pre>\n",
       "<p>This library is a Python wrapper around the high-performance librdkafka C library, making it one of the fastest Python clients available for Kafka.</p>\n",
       "<h3>2. Additional Useful Libraries</h3>\n",
       "<p>If you're working with Avro serialization (a common format used with Kafka):</p>\n",
       "<pre><code class=\"language-bash\">pip install fastavro\n",
       "</code></pre>\n",
       "<h3>3. Alternative Python Kafka Libraries</h3>\n",
       "<p>Although not mentioned in our FAQ database, there are other popular Python Kafka clients you might consider:</p>\n",
       "<ul>\n",
       "<li><p><strong>kafka-python</strong>: A pure Python implementation</p>\n",
       "<pre><code class=\"language-bash\">pip install kafka-python\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>PyKafka</strong>: Another client library</p>\n",
       "<pre><code class=\"language-bash\">pip install pykafka\n",
       "</code></pre>\n",
       "</li>\n",
       "</ul>\n",
       "<h3>Important Notes:</h3>\n",
       "<ul>\n",
       "<li>The Confluent Kafka client is generally recommended for production use due to its performance.</li>\n",
       "<li>If you're experiencing issues with your Kafka broker connections, make sure your Kafka broker is running correctly. If using Docker, check with <code>docker ps</code> and start it with <code>docker compose up -d</code> if needed.</li>\n",
       "<li>Some libraries like Faust (once popular for Kafka stream processing in Python) are no longer maintained.</li>\n",
       "</ul>\n",
       "<p>Would you like me to provide more information on how to use these libraries after installation, or do you have a specific use case for Kafka with Python that you'd like help with?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "await runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59d305-5ae8-492b-b02d-69474b9da412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
