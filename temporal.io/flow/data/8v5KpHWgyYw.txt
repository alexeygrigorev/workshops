Becoming a Data-led Professional

0:00 So actually I have a slightly updated
0:03 slide deck. So this is exclusive
0:06 material now. So in these pictures by
0:08 the way my wife drew them
0:11 like these pictures that now they're on
0:14 the website. So I think they should
0:17 illustration.
0:18 Okay. Yeah. Let's start. So thanks
0:21 everyone for joining us today. So this
0:23 event is brought to you by data talks
0:25 club which is a community of people who
0:26 love data. We have weekly events and
0:29 today is one of such events. So we have
0:31 interviews on Friday and we have
0:33 webinars on Tuesday. If you want to find
0:36 out more about our events, you can go to
0:38 our website uh which you can also find
0:40 in the description section which is data
0:43 talksclub/events and you can find all
0:45 the events that we uh plan um for next
0:49 weeks. And also on the page you'll find
0:52 a link to our Google calendar. If you
0:54 don't want to miss any events, um you
0:56 can just uh subscribe to our calendar
0:58 and you will get notified about all the
1:00 events. Or if you don't like and you
1:03 just want to subscribe to individual
1:04 events, you'll find all the events in
1:06 the events page.
1:09 Also, to stay upto date with everything
1:11 uh in our channel, um you should
1:14 subscribe it. So, just click on the
1:15 subscribe button. And last but not
1:18 least, uh if you haven't joined our
1:20 Slack, please do. It's uh awesome. There
1:23 we talk about different data related
1:26 topics. If you have any questions during
1:29 today's uh conversation, you can ask any
1:32 question in uh slido. So there is a
1:35 pinned link in live chat. So you just go
1:37 there, you click on this link and you
1:39 ask any question you want and we will uh
1:41 cover these questions as we um as we go.
1:45 And last thing uh I asked RP2 to to keep
1:49 an eye on our uh uh events Q&A channel.
1:53 So I know that many of you are watching
1:54 this uh the events in recording and you
1:59 do not get a chance to ask questions. So
2:02 if you watch this event in recording and
2:05 you want to ask something, you can go to
2:06 our Slack events Q&A channel and ask
2:09 your question there.
2:11 And uh that's all for the introduction.
2:13 Um uh we can start. Are you ready?
2:17 Yeah, absolutely.
2:19 Okay, so
2:23 I have my notes.
2:25 So this week we'll talk about becoming a
2:28 data professional and we have a special
2:31 guest today, Arbit. And u for those who
2:34 don't know, Arbit actually is one of the
2:36 first people who joined data talks club.
2:39 I think uh maybe you were one of the
2:41 first 10 or 20 something like this and I
2:43 remember asking you some tips uh uh
2:46 because your title is uh uh like I
2:49 checked your LinkedIn and it was uh
2:52 something about uh growth and uh
2:54 community
2:55 community and of course uh I immediately
2:57 became interested and started to ask you
3:00 different questions about hey how do I
3:01 grow the community
3:03 and Arpit is also a founder the founder
3:06 of datallet academy which is a to go
3:08 place for any everybody who is
3:10 interested in data, who wants to learn
3:12 how to work with data, how to
3:15 um to to learn everything about data and
3:20 you want to ask any data related
3:22 question. Uh and uh this is the place to
3:26 look for answers. So, welcome Arbit.
3:28 Yeah, thank you. Uh thanks Alexi for the
3:30 for the intro. Excited to be here. Uh
3:32 thanks for having me. I think uh data
3:34 data talks is a really great community.
3:36 um excited to be part of it and just to
3:39 let people know data academy is not
3:41 exactly a community. It's not a slack
3:43 community but essentially it's a place
3:45 to uh learn how to work with data. So we
3:47 have like a lot of free learning
3:49 content. Um and then we're also creating
3:52 a repository of you know common
3:53 questions that people have about tools,
3:55 technologies, people and processes
3:57 related to data. So you can like go and
3:59 find uh these these uh you know answers
4:01 to those questions there. Um so excited
4:04 to be here. Thanks again. And you also
4:07 have a podcast which you
4:09 Yeah. Yeah. So we have a podcast called
4:11 Yeah. It's actually called the data
4:13 professional. Uh so you can check out
4:15 the podcast on our website
4:16 datalet.academy/mpodcast.
4:19 Um and we basically talk about different
4:21 data related topics. U primarily focused
4:24 on topics that are relevant for uh I
4:27 like to use term less technical people.
4:29 People who are not exactly uh data
4:32 engineers or data analysts. Of course,
4:34 they can also benefit from the content
4:35 where our core audience is basically uh
4:37 people working in product growth and
4:39 operations roles or marketing uh who
4:41 want to basically learn about data and
4:42 like you know different data related
4:44 topics. Um and typically you know our
4:47 goal is to answer again common questions
4:49 that people have um about about data.
4:53 Yes. Uh so before we go into our main
4:57 topic of data of becoming data uh maybe
5:00 we can start with your background. Um
5:02 can you tell us uh about your career
5:04 journey so far?
5:06 Yeah, absolutely. Uh so so basically um
5:08 I've been working in the technology
5:10 industry for for pretty much the whole
5:12 my whole career but I've I've sort of
5:14 you know worked in in different types of
5:16 companies. U I really got into the data
5:19 space uh when I when I I was basically
5:22 working as a consultant and you know I
5:24 was building a lot of integrations for
5:26 SMBs um and that led me to to
5:29 Integramat. I was a user of Integramat.
5:31 Integramat is a is an iPad solution like
5:34 like Workardo, Trey, Zapier, etc. Um and
5:38 I was like one of the earliest people to
5:39 join the Integramat team. Uh I actually
5:42 built the Integramat community and then
5:43 eventually I led growth at Integramat.
5:46 Um I I moved on from Integramat uh soon
5:49 after it got acquired late last year. uh
5:52 since then I worked with a few other
5:54 companies um basically again companies
5:58 in the data space solving different
6:00 problems in the you know customer data
6:02 infrastructure sort of space um and and
6:05 um and now I'm I'm building data lit
6:07 academy while while also you know
6:09 working with a few data companies
6:11 helping them with their content and
6:13 community strategy for me content
6:15 community is is really uh is all I've
6:17 been doing you know like integral matter
6:19 also content community is what helped us
6:22 grow um really really fast and um and
6:25 and it's really important for for uh you
6:28 know especially data companies to to
6:30 build their presence across different
6:32 communities uh where where their
6:34 prospects customers partners hang out
6:37 communities like data talks club um you
6:39 know instead of building a new community
6:41 a lot of people are building new
6:42 communities but I believe that there are
6:44 already a lot of great communities and
6:47 um and that's why I I like to you know
6:50 be active in exist distinct communities.
6:52 Um and and that's that's the idea behind
6:55 Natalet Academy to to not build another
6:57 community but but basically sort of
7:00 create a place where people can um get
7:03 get concrete expert actionable uh
7:06 actionable answers expert unbiased
7:08 actionable answers to their questions.
7:10 Uh and a lot of these answers are
7:11 basically answered by experts uh who are
7:14 from these communities. So yeah that's
7:16 that's a bit about uh my my background.
7:21 Mhm. Yeah. Thanks. Uh so as uh so this
7:25 term growth and this is something you
7:27 did uh at Integramat.
7:30 So I was curious what actually growth
7:32 managers do and when I checked
7:35 it's very uh it's uh very datadriven. I
7:39 don't know how to describe but they use
7:40 a lot of data. So um judging like when I
7:43 look at the title growth manager or
7:46 growth market marketing it doesn't sound
7:49 too data related to me but when I
7:51 actually read and they they run a lot of
7:53 baby test they need to make a lot of
7:55 decisions all these decisions are based
7:56 on data
7:58 uh yeah so I guess this is how you um
8:01 you ended up creating this uh data
8:04 academy right so because you saw how it
8:06 is useful uh okay
8:09 yeah yeah without data you can't really
8:11 I mean there there's only so much you
8:13 can do. I shouldn't say you can't do
8:14 anything but there's only so much you
8:15 can do. uh like uh in simple terms like
8:18 if you don't have data uh when you're
8:20 building growth experiences whether it's
8:22 for you know acquisition, activation um
8:25 or retention or whatever you're without
8:27 data you'd be forced to build linear
8:30 experiences you know like every customer
8:32 irrespective of their behavior uh they
8:34 will go through the same path right but
8:36 when you have data you can actually
8:37 create personalized experiences where
8:40 customer prospects will will see content
8:42 or or interact with your product based
8:45 on you know where they come from, what
8:47 their uh industry is and and how they
8:50 basically interact with your product. Uh
8:51 so that is the main difference and and
8:54 uh it's very hard for for growth
8:56 professionals or or even product
8:57 managers to to really you know u build
9:01 personalized customer experiences across
9:04 different c u you know m across
9:06 different touch points and channels
9:08 without having access to data uh and
9:11 having access to data in the tools that
9:13 they use. Um it's not just enough to
9:15 have access to data in a data warehouse
9:17 or a BI tool. Uh it's more important
9:20 than ever to have access to data in the
9:21 tools that they use to to build and
9:24 craft these uh customer experiences.
9:28 So tools that marketers use to make
9:30 different decisions, right? because they
9:32 cannot just go and uh uh or most of them
9:35 probably I don't know u but most of the
9:38 marketers I worked with they cannot just
9:40 go and uh run a SQL query in
9:44 a database right so they need help for
9:46 that
9:47 yeah marketers growth professionals
9:48 product people operations people they
9:51 they they need not really know how to
9:53 write SQL of course if they know it's
9:55 it's an added advantage but uh um there
9:57 are a lot of great tools out there that
9:59 allow you to you know visually query the
10:01 data Um so if the data is is made
10:03 available then then they can easily sort
10:05 of use the data uh for for their their u
10:10 for for for whatever they're doing. So
10:11 whether it's uh uh creating in-app
10:14 experiences or or creating life cycle
10:16 email campaigns or um you know doing AB
10:20 test like you mentioned um or or doing
10:23 like an SMS campaign for example um
10:25 irrespective of the channel that they're
10:27 using to engage with customers they can
10:30 sort of use this this data if the data
10:32 is available in the tools that they use
10:35 um yeah
10:38 so what is data so
10:41 I I think you have a definition, right?
10:43 So what is that?
10:45 Yeah. Yeah. So my definition of data is
10:47 basically a data professional or data
10:50 person is someone who who understands
10:52 where where data comes from, what it
10:54 looks like. Um they're able to question
10:56 its accuracy, you know, not just blindly
10:58 believe the data that they see. So if
11:00 they understand where data comes from
11:02 and what it looks like, uh they'll be
11:04 able to question its accuracy. And then
11:05 of course they are comfortable working
11:07 with data. Um and you know they have the
11:10 skills to build these experiences
11:12 powered by data. Um so so it sounds like
11:16 you know a lot but essentially it's you
11:18 don't really need a technical background
11:20 I would say to to to know any of this
11:22 stuff to understand where data comes
11:24 from what it looks like to question its
11:26 accuracy um and to to basically work
11:28 with data to build data experiences.
11:32 Mhm.
11:33 Is there any difference between being
11:35 datadriven and data? U data driven is
11:39 something I hear quite often and to be
11:42 honest I still have no idea what it
11:44 actually means. I think sometimes it's
11:45 used like a buzz word. Uh
11:47 it is a buzz word.
11:48 Okay, we're datadriven and what does it
11:51 mean? And uh yeah maybe you can just
11:53 explain a bit what it means and what are
11:56 the differences between datadriven and
11:58 data if there are any differences.
12:00 Yeah. Yeah. uh like you said it is sort
12:02 of a buzzword uh but like how I like to
12:06 think of data driven is basically uh to
12:08 to base decisions exclusively on
12:10 available data you know every company
12:12 wants to be data driven so they they
12:14 they're investing heavily in data
12:15 infrastructure uh once data is available
12:18 they they want to like like to be data
12:20 driven would be to to not again question
12:23 the accuracy of the data and uh not use
12:26 your intuition and experience before
12:28 making decisions you know like uh data
12:31 is all about making decisions. It helps
12:32 you good data helps you make good
12:34 decisions. But you cannot always blindly
12:37 follow what data tells you because you
12:40 know like there are there's so many ways
12:42 um you know the data that you see can be
12:45 inaccurate. Um there are so many data
12:47 quality issues that can be there. Um so
12:50 it's important to to to basically
12:52 combine your intuition, your experience
12:54 along with the data that you see. So
12:56 that I would say is the difference
12:57 between being data driven versus being
12:59 data led where where data is leading you
13:02 or guiding you rather rather than just
13:05 you know telling you just you know
13:06 blindly following what data tells you.
13:08 Mhm. So it's uh that part uh where you
13:12 said like data professional somebody who
13:14 knows understands where the data comes
13:16 from can question uh its accuracy and
13:20 comfortable working with data. So I
13:22 guess the the second point about
13:24 questioning is the main uh the main
13:27 factor that say that different
13:30 differentiating factor right between
13:32 these two.
13:33 Yeah. Yeah. And you can only question it
13:35 accuracy if you if you understand you
13:37 know where data is being collected or
13:38 how it is being collected. Uh if if
13:41 nothing is documented you you can't
13:43 really understand anything. So you can't
13:44 really question it. So it's very
13:46 important to to have um you know proper
13:49 documentation on on your on your data
13:51 sources. Uh one of the thing that we
13:53 talk a lot about especially in the
13:55 context of product and growth is having
13:57 a data tracking plan uh which
13:59 essentially is a it could be a simple
14:00 Google doc um or Google sheet or you you
14:03 know there are purpose-built tools now
14:05 to create your tracking plans where you
14:08 uh define every event that is being
14:10 captured um and and you know related
14:13 properties that are being captured and
14:14 even the data types of each property. So
14:16 when these things are are well defined
14:19 um any product or growth professional
14:21 can can look at that that information
14:23 and understand that okay uh this event
14:26 is captured when someone perform this
14:28 particular action. You know the sign up
14:30 event is is captured when someone um not
14:33 just submits the signup form but when
14:35 when when the when when the sign up is
14:37 completed rather than than just you know
14:40 being a client side event versus being a
14:42 server side event. So when you specify
14:44 these things you enable people to to
14:47 understand where data comes from you
14:49 know um so that's really important like
14:52 documenting everything uh to be able to
14:54 like you know pass on that knowledge to
14:56 others because you know the person who
14:58 would implement it they they cannot be
15:00 around forever to to explain to people
15:02 you know where data is coming from but
15:04 and once you have that understanding
15:06 then then you're able to question the
15:08 accuracy when you see uh an anomaly when
15:11 you see that the data doesn't look right
15:13 you can actually, you know, go and like
15:15 drill down and figure out what the issue
15:17 is. Um, instead of just flying blind or
15:20 just, you know, blindly trusting what
15:22 you see.
15:25 So for this, um, so you mentioned this
15:27 data tracking plan and document which
15:30 describes all these events. So how do
15:32 you uh like when do you actually need to
15:35 do this? So let's say you're uh is it
15:38 for startups or is it from mature
15:40 organizations like uh I guess uh for any
15:43 type of company they already have some
15:45 data sources. So something is already
15:47 going on on the platform
15:49 and then uh they hire I don't know a
15:52 growth marketer right somebody who comes
15:54 in and now needs to uh make decisions
15:57 based on data right and uh and
16:01 so I yes
16:02 so I would say it depends I mean depends
16:04 on the stage of the company like uh I've
16:06 seen some some big companies not having
16:09 a tracking plan at all uh which is a
16:11 problem so essentially every company
16:13 that has has a tech product or a tech
16:15 enabled product or even an e-commerce
16:17 business needs to have u this documented
16:20 uh whether it's a tracking plan or uh
16:22 some companies use use like other
16:24 different like different tools to sort
16:26 of document this they use tools the
16:27 visual tools like miro and stuff um
16:30 so it's it's usually done even before
16:33 you instrument uh you know like data
16:36 before you set up instrumentation before
16:38 you set up like product product
16:40 analytics
16:41 so instrumentation in the sense like uh
16:43 before you set up let's say a product
16:45 analytics tool or any any tool that that
16:47 that uh that depends on event data. Um
16:51 you instrument uh your product events,
16:53 you know, like the the the process of
16:56 tracking uh product data is is of often
16:59 referred to as instrumentation. Um so
17:01 this is usually done again there's no
17:04 rule when it's done but it's typically
17:06 done when companies are ready to sort of
17:08 invest in uh product analytics tools or
17:11 or like uh other other event- based
17:13 engagement tools like customer eye or
17:15 braze etc etc so many tools where you
17:18 can like you know use events to
17:20 personalize customer experiences so um
17:24 and this is something that that
17:25 obviously is relevant to startups as
17:26 well as big companies more so with with
17:29 big companies because at a big company
17:31 if you don't have have this stuff uh
17:33 documented like like people will new
17:36 people will come in and they they'll
17:37 have no idea uh what to do with with
17:40 your with the tools. They'll see a bunch
17:42 of like events, let's say in intercom,
17:44 uh, and they're supposed to create some,
17:47 uh, you know, inapp experiences or some
17:49 email campaigns, but they won't know
17:51 what an event means, right? Uh, or they
17:54 might see conflicting events. They might
17:56 see an event called signed up, another
17:58 event called um, you know, signed up
18:00 with a different casing. Um, so so all
18:02 of those issues sort of come up if you
18:05 don't have things documented and well
18:07 instrumented. So um like I I would
18:11 recommend every company to do this
18:12 sooner rather than later because um of
18:15 course you need to sort of have
18:17 customers and you need to have users to
18:19 be able to um you know make sense of
18:21 this data otherwise you set it up but
18:23 there won't be any data to to analyze or
18:25 act upon.
18:26 Mhm.
18:27 Yeah. So I I think I mentioned this
18:30 growth marketer but there are any like
18:32 there are a lot of different users of
18:33 data. So we have the data analysts, we
18:35 have product managers, uh basically
18:38 everyone who needs to make a decision
18:39 certain decision on data, they would
18:41 need to to analyze the data and they
18:44 would need to uh understand the each
18:48 event right so what is the origin of
18:50 this event and I think you mentioned if
18:52 the they see something strange in the
18:54 data they need to be able to question
18:56 this okay like uh there is a spike in I
18:59 don't know registrations or something
19:01 like this or in certain type of event
19:03 Okay, what does it mean? Right? And then
19:05 they would be able to go and uh drill in
19:09 and understand what what's happening,
19:11 right?
19:12 Yeah, absolutely. An example would be
19:14 let's say you see a spike, a ridiculous
19:16 spike in in your signups um and you know
19:19 that it it doesn't look right. If you
19:21 have uh the the event instrumented
19:23 properly and you're also capturing
19:25 relevant properties with that event, you
19:27 can actually figure out where the
19:28 signups are coming from. Um and
19:30 oftentimes you might realize that you
19:32 know these are like fake signups or like
19:34 bots. Uh this something a lot of
19:35 companies have have been experiencing.
19:37 So you'd be able to do that. Um another
19:40 thing that I would like to mention is
19:41 that you mentioned product growth and
19:43 we've been talking about product
19:44 marketing growth people. But u product
19:46 data event data is extremely useful for
19:48 even for sales people today. Uh so sales
19:51 people look at a CRM uh they they look
19:53 at you know data about a company or
19:55 about a prospect. Um but when they have
19:58 access to product data where they can
20:00 see what a prospect uh in the trial
20:02 period is doing inside the product it
20:04 gives them more more context and then
20:06 they can like go after the right
20:08 accounts rather than you know again just
20:10 going after everybody who's a prospect
20:12 in their CRM when they see that you know
20:14 this particular account has you know uh
20:16 they already have five users in their
20:18 account and they've already gone ahead
20:19 and like you know performed a bunch of
20:21 actions. uh if it's a project management
20:23 tool, they've already gone ahead and
20:24 created a project and created a bunch of
20:26 tasks. Um so now would be a good time to
20:28 sort of reach out to them uh versus just
20:32 again reaching out to everybody who just
20:34 shows up in your CRM and you know maybe
20:36 based on the company size or or
20:39 whatever. So it's extremely useful for
20:42 for for even for sales or um yeah like
20:44 sales and BD people.
20:48 Okay. So um this is very important to
20:51 document your data right and we
20:54 discussed I think you mentioned that you
20:55 can do this with miro uh I think I saw
20:58 some
20:59 things like that uh in like just an
21:03 expel Excel spreadsheet or not
21:05 necessarily Excel but maybe Google
21:06 spreadsheet like some online
21:08 spreadsheets
21:09 are there any special tools for that or
21:12 people use whatever uh they're
21:14 comfortable with
21:15 no so now there are like purpose tools
21:18 for that. So uh there's one called AO so
21:21 AO there's another one called itatively
21:23 uh there's the new one called track plan
21:25 I can share these names on Slack um so
21:28 you know people can explore these tools
21:30 so these are actually tools that are
21:33 especially built for companies to create
21:35 their tracking plan in a collaborative
21:36 manner rather than relying on a on a
21:38 spreadsheet. So they obviously have a
21:40 lot of you know features that are really
21:42 useful that that enable you to maintain
21:44 data quality, maintain a taxonomy, um
21:47 you know like collaborate on each event.
21:49 A lot of times you you might describe an
21:51 event and and the developer who's
21:54 supposed to instrument it uh they might
21:55 have questions about that event. So you
21:57 can like discuss stuff. Uh so these
21:59 tools are really really useful I would
22:01 say and they're worth exploring. Mhm. So
22:04 I'm I'm really So you said a developer
22:07 who is supposed to instrument this
22:09 event. So the way I interpret I
22:11 interpret it the way I understand it is
22:13 so first you create this tracking plan
22:15 right. So you um
22:18 you take you write down all the events
22:21 all the type of events you want to
22:22 capture. It doesn't mean you capture
22:25 them yet but you want to start tracking
22:27 them right and then uh there is a
22:29 developer or maybe a mobile developer.
22:32 Yeah, some engineer
22:34 uh who now needs to go and implement
22:36 this to start tracking this data, right?
22:39 So because the data doesn't just appear
22:41 magically on your dashboard, right? And
22:43 then you make a decision, you actually
22:45 need to capture this data
22:47 and do many many other things, right? So
22:50 maybe we can talk a bit about this like
22:54 okay now we have a tracking plan and now
22:55 a developer u
22:58 we tell a developer hey can you please
23:00 instrument this event can we start
23:02 collecting that and then we have the
23:04 other end of uh this is like an analyst
23:07 or somebody is looking on a dashboard
23:10 and now can make a decision like this
23:13 campaign uh this type of campaign this
23:15 variant of a campaign is better than
23:16 this variant of campaign right so then
23:18 we can make a decision and there is a a
23:22 big like a lot of things happen between
23:24 these two these two right so
23:27 yeah absolutely so I would say like data
23:30 collection is the first step and and
23:32 even before you know like let's talk
23:34 about a startup um that doesn't have any
23:36 any data infrastructure in place uh
23:39 let's let's think of a SAS product could
23:41 be a project management tool or or
23:43 invoicing tool um before you implement
23:46 uh any any any tools any like product
23:49 analytics tools or or any tools that
23:50 rely on data. You need to first create a
23:52 tracking plan and describe you know all
23:54 the events that you want to capture and
23:56 then describe all uh the properties you
23:58 want to capture with every event. You
24:00 also want to describe your your user
24:01 properties and you also want to describe
24:03 uh organization or account properties.
24:05 So all the different pieces of data that
24:07 you ideally want to collect and uh this
24:10 is really important because when you
24:11 start doing this you you you feel like
24:13 you want to collect this also and that
24:15 also you might end up with like 50
24:17 events um and which is great but the
24:19 next step is to basically remove all the
24:22 events that you don't need in the near
24:24 future because you know having too much
24:26 data at the beginning is is like one of
24:28 the biggest uh issues. It also obviously
24:31 takes more time to implement it takes
24:33 more time to test. So like bring it down
24:35 to like seven or 10 events that you
24:37 really really need to understand the
24:39 customer journey from acquisition to
24:41 activation.
24:42 Maybe we can think of some examples. So
24:45 you said like a SAS product which could
24:47 be a product project management tool or
24:50 account like accounting tool or
24:52 something like this.
24:53 Yeah. So if it's a
24:54 Yeah. Sorry. Go on.
24:56 Yeah. So yeah, I was going to suggest
24:58 maybe we can take one of the tools. I
25:00 think it you set invoicing tool that
25:02 probably makes Let's take project
25:04 management. Okay. Yeah. Invoicing either
25:07 way. So, so you start by you start by
25:09 obviously tracking your your sign up
25:11 event, you know. Um sometimes I I
25:14 recommend people do even track u the
25:16 event which is email verified because
25:18 you know u depending on how your signup
25:20 flow is. You might not always you might
25:22 have people who who sign up but they
25:24 don't end up verifying your email. So
25:26 it's useful to have that because you
25:27 might want to like create some emails
25:30 based on that event. So like sign up,
25:32 email verified. Um if it's a project
25:34 management tool, obviously the one of
25:36 the first things is to create a project
25:38 and then add uh invite a user because
25:40 you know a project management tool is no
25:42 good if you don't if someone doesn't
25:44 invite another user to work with. So
25:46 like you know project created, user
25:48 invited uh those would be like the the
25:50 core events that you track. And then of
25:52 course you also want to see uh whether
25:53 they create a task. So, you know, task
25:55 created. If it's an invoicing tool,
25:57 again, it could be uh an invoice created
26:00 or or like uh with an invoicing tool,
26:02 you probably add a client. So, it could
26:04 be client added or client created and
26:07 then invoice created and then you want
26:09 to maybe again invite your colleagues.
26:11 So, user invited. So, these are the most
26:13 common events. Um
26:15 um so yeah like you you definitely start
26:18 with these for each event you'd describe
26:20 relevant properties. Uh so for the
26:22 signup event you you obviously want to
26:24 describe um the user's name and email
26:26 but also uh if you're if you're asking
26:29 the user so let's say there's a signups
26:30 form where you're asking the user which
26:32 industry they belong to um and what is
26:34 their roles you definitely want to
26:36 capture that information uh alongside
26:38 that event. So stuff like that. Um, so
26:41 yeah, once you have that, once you're
26:43 happy with your once you're happy with
26:45 your events, that's that's when you you
26:48 basically bring in an engineer and then
26:50 you basically discuss it with them. Uh,
26:52 get their feedback. Of course, engineers
26:54 have a lot of good feedback. Um, you get
26:56 their feedback, polish your tracking
26:58 plan. Once you agree upon it, you you
27:00 basically even like I highly recommend
27:02 you to even describe for every event,
27:04 describe whether it's a client side
27:06 event or a server side event. That's
27:07 really really important. It's obviously
27:09 now better to to track more events
27:12 server side but you might want to track
27:14 some client side events. So it's
27:16 important to describe that so that you
27:17 know
27:17 what's the difference
27:19 like sign up is a client side or server
27:22 side. So it depends how how how you end
27:25 up implementing it, right? Like if
27:26 you're tracking it client side, the
27:28 event will be fired as soon as someone
27:30 clicks the sign up button, you know,
27:31 submits the form. But if you're tracking
27:33 server side, it'll only be fired once
27:36 the signup process is actually completed
27:37 on once that user is actually added in
27:39 your database. You know, like a lot of
27:41 times a lot, you know, users will click
27:43 that sign up button and there'll be an
27:44 error that you need to there might be a
27:46 validation error that, you know, your
27:48 password is not right or email is not
27:49 right, but the event will be fired. So
27:51 you might see a signup whereas an actual
27:54 signup hasn't even taken place, right?
27:56 So uh so you'd ideally track their
27:58 server side, but there might be uh for
28:01 some use cases for for tracking client
28:03 side events um where you actually want
28:05 to track if someone clicked a button. Uh
28:08 this is usually useful inside your app.
28:10 If you want to see if someone tried
28:12 clicking on a button to use a feature,
28:14 uh even if they don't don't use the
28:15 feature, you want to know that someone
28:17 actually tried using it. So that's like
28:19 useful information for you. So that
28:21 could be a client side event. Yeah.
28:26 Um so yeah once you have that I would
28:28 recommend that you know once you start
28:30 working with your engineers um often
28:32 there might be multiple engineers
28:34 involved. So you should even specify you
28:35 know which engineer which engineer is
28:37 going to implement which event. So you
28:40 can have a column or you can specify who
28:42 owns which event. Um once you have
28:45 everything done and once you actually
28:46 have data flowing in um you you're
28:49 actually sort of done with the with the
28:51 collection stage uh the next step is to
28:54 obviously make sure that this data that
28:56 is being collected is being stored in a
28:57 warehouse. Um of course for for early
29:00 stage startups it might not be possible
29:02 to to to set up a warehouse although
29:04 it's you know it's not hard at all to
29:06 set up a warehouse today. It's also very
29:07 affordable. Uh so it's very it's highly
29:10 recommended to to uh store this event
29:13 data or product data in a warehouse
29:15 because if you don't you you'd obviously
29:17 be sending it to let's say a product
29:18 analytics tool like like mix panel or
29:21 amplitude or whatever um and a few other
29:24 tools but you won't really have access
29:26 to this raw event data to be used in the
29:29 future. So uh s recommended that you
29:31 store it um and then of course you want
29:34 to analyze this data. uh typically uh
29:36 event data is analyzed in a product
29:37 analytics tool. Uh some people also end
29:40 up doing this in a BI tool but BI tools
29:43 are not you know purposebuilt to analyze
29:46 event data. So uh you'd obviously sort
29:49 of need need an analyst who would have
29:51 to write a whole bunch of um uh SQL
29:54 queries to to actually create let's say
29:57 a simple funnel uh report in a BI tool
29:59 that you could do in a product analytics
30:01 tool with a few clicks. So um
30:04 irrespective of the tools you're using
30:05 to analyze the data you you basically
30:07 analyze it and you derive insights uh uh
30:10 from from that data and then of course
30:12 you want to activate that data or act
30:14 upon that data u and that's obviously
30:16 the most important thing like you can't
30:17 just look at data and be happy with it
30:20 you need to do something about it um and
30:22 that's when um data activation sort of
30:25 comes into place and once this data is
30:28 available in your activation tools uh
30:30 your email tools your your uh support
30:32 tools. Uh support is a really good use
30:34 case like something that a lot of people
30:37 don't think about but if you make this
30:39 event data available in your support
30:40 tools you actually enable your support
30:42 teams to actually see what users have
30:45 done in the product. So they don't have
30:47 to like you know ask people uh when when
30:50 someone opens a ticket they don't have
30:51 to reply saying hey did you try doing
30:52 this or did you try doing that or can
30:54 you try doing this because they can
30:56 actually see uh the different events
30:57 that users have performed so they don't
30:59 have to you know you can provide better
31:01 support companies who actually have this
31:04 because
31:06 all my experience with customer support
31:08 uh says that none of them
31:11 more and more companies realize the
31:13 importance of this is just obviously you
31:15 know it's It's not a priority for most
31:17 companies, but of course there are many
31:19 companies um that that that provide
31:21 great support. They have this and it's
31:23 really not hard once you have the data.
31:25 You just have to sort of send this data
31:27 to Zenesk or whatever uh support tool
31:29 you're using. Um so that's the thing
31:32 with data, right? Like every company or
31:34 let's say 100 different companies will
31:37 have access to to this data but maybe
31:38 only five of them are actually using
31:40 this data across different sort of
31:43 channels and and um making this data
31:45 available to different teams right uh
31:47 even the sales example is is really
31:49 important useful um sales people don't
31:53 generally have access to product data in
31:55 the tools that they use right but now
31:57 more and more companies realize that the
31:59 importance of this and now they're like
32:01 a new breed of companies that have that
32:03 have come up that are building sort of
32:06 uh uh these these new tools which are
32:08 now sort of dubbed as CRM 2.0 tools
32:12 where uh sales people can can uh
32:15 actually access product data and and um
32:18 you know be more sort of responsive uh
32:21 and like they don't have to just create
32:23 sort of these linear experiences. So um
32:27 so yeah uh once you once you're once you
32:29 have the data and the right tools you
32:30 can activate the data and you can you
32:32 know build these really good
32:34 personalized customer experiences and
32:36 then of course you can send this data
32:37 back to your product and and personalize
32:39 uh the product experience also you know
32:42 based on uh like I think HubSpot is a
32:45 really good example there are a bunch of
32:46 other companies that do this really well
32:48 where uh the way people experience the
32:51 product is also depend also sort of
32:54 personal ize based on what they've done
32:57 earlier in the product, you know. So
33:00 that is that is the ultimate sort of uh
33:03 destination where where you're not just
33:05 like analyzing data and using it to to
33:08 create experience outside your product
33:10 but also inside your product. Um it's
33:13 worth mentioning that uh tools like
33:15 amplitude uh which is obviously one of
33:17 the most popular product analytics tool
33:20 um has launched a new sort of a product
33:22 or a feature called amplitude recommend
33:25 where you can actually do this um using
33:28 amplitude where you can send the data
33:31 from amplitude into your back to your
33:34 product and of course to to other tools
33:36 um to to create like a unified customer
33:39 experience.
33:40 Yeah. So uh maybe we can take a step
33:43 back you like there was a lot of
33:45 information and they have so many
33:46 questions uh but starting even from the
33:49 the beginning. So you said for tracking
33:52 plan uh for creating this tracking plan
33:54 we can use u you mentioned a tool I
33:56 think called track plan right and there
33:59 are some other things
34:00 then um then okay we have this tracking
34:02 plan then a developer an engineer would
34:05 go and implement this uh do data
34:07 collection
34:08 um I know are there specific tools uh
34:11 for that uh uh for collecting data
34:15 u so typically like of course there are
34:17 there are sort of CDI tools uh you know
34:19 customer infrastructure tools. Customary
34:21 infrastructure tools that so the ones I
34:24 mentioned track plan is one but aro and
34:26 iteratively sort of the these are tools
34:29 that that allow you to also collect your
34:31 data not just create the track and plan
34:33 but other popular tools would be segment
34:35 connections. So segment connections is
34:37 one of the most popular tools people use
34:39 to to track product data. Um there's
34:42 also rudder stack. Uh there's another
34:44 one called meta router which is
34:46 relatively new. Um there a whole bunch
34:48 of tools there. There's one called fresh
34:50 paint which which uh which enables
34:53 implicit tracking. So you don't even
34:55 have to define tracking. There's this
34:57 like autotrack. Once you install it, it
34:58 starts tracking all the events
34:59 automatically uh like heap does. Um and
35:03 then of course companies companies do
35:04 this using code and you know some some
35:06 companies build a micros service just
35:08 for the tracking purposes. Um but then
35:11 of course there are all these great
35:12 tools that I mentioned. Um in fact I
35:15 have I have I have uh I have written
35:17 about this but happy to I'd be happy to
35:19 share uh this content and
35:21 please send the link and I'll include it
35:23 in the description. Um
35:25 yeah for sure.
35:26 So and then you mentioned that we the
35:28 data should be that the data we collect
35:31 we can send immediately to uh product
35:34 analytics tool but it's better to store
35:36 it in a warehouse. So what is a
35:38 warehouse? I think it's essentially like
35:40 a database that you own right. So it's
35:43 not like a third party tool but yeah
35:46 maybe you can tell in uh you
35:50 tell us what is it's it is it any
35:53 database or it's some sort of special
35:54 database. Yeah. So, a data warehouse is
35:57 generally a database that is
35:59 purpose-built for analytics, right? So,
36:01 it's not like a like a typical uh
36:04 database. Um, and companies use it to to
36:06 store uh large amounts of structured
36:09 data. Um, and then they obviously uh
36:12 create data models in the data
36:14 warehouse. So, they transform the data,
36:16 they clean the data, there of course
36:17 other tools just for transformation
36:19 purposes, tools like DBT, trifactor etc.
36:22 which you know you're you're well aware
36:23 of. Um and once you have this clean
36:26 structured data in the warehouse, you
36:28 can basically analyze this data in a BI
36:31 tool. It's also worth mentioning that uh
36:33 there are product analytics companies
36:35 that are now sort of warehouse centric.
36:38 Uh so if you if you have a warehouse and
36:40 you if you already if you're already
36:42 sending data to your warehouse and you
36:43 want to implement a product analytics
36:45 tool, you don't have to use their SDKs
36:47 to to sort of send data to them
36:49 directly. You can send data from your
36:51 warehouse uh to these product analytics
36:53 tools. There's also a tool called
36:54 Rockcom which uh doesn't even you don't
36:57 even need to send data to it. It just
36:59 sits on top of a warehouse like a BI
37:01 tool and offers broader analytics
37:03 features. So um it's really important to
37:05 set up a warehouse and uh popular
37:07 warehouses I was mentioning are
37:09 obviously snowflake bitquery AWS red
37:12 shift there's some new ones called uh
37:14 firebolt is a newer data warehouse in
37:17 fact we have someone from firebolt in
37:18 our community um and then
37:21 I think I saw recently also in data club
37:25 right yeah in your exactly that's what I
37:27 mentioned that's what I meant and then
37:29 there bunch of other of course warehouse
37:31 uh vendors there's one called panly
37:34 Uh so once you have the data in the
37:36 warehouse you can actually do do a lot
37:38 of things with it um and you can
37:40 actually send it back to your uh not
37:42 just BI tool but also product anal
37:44 analytics tools and then um you can even
37:47 send it to your engagement tools. Uh and
37:49 there again new bunch of uh company that
37:52 have come up that are just solving this
37:54 problem. Uh they're sort of referred to
37:56 as reverse ETL tools or or operational
37:59 analytics tools. companies like Fensus,
38:01 High Touch, Grouperoo, um they are
38:04 they're basically solving this exact
38:05 problem that you have the data in the
38:07 warehouse and you want to basically send
38:10 data to to a lot of different tools,
38:12 your sales, marketing, uh advertising
38:14 support tools or whatever, product
38:15 analytics tools, you can do that um
38:18 using this this third party tool. So
38:21 yeah, there a lot of different tools
38:22 solving different pieces of the puzzle.
38:25 Uh, of course, like to implement all of
38:27 these different tools, you'd uh need
38:29 like a lot of resources. You'd need a
38:31 data team, um, at least couple of or
38:33 maybe at least one dedicated data
38:35 engineer. Um, so it's not possible for
38:38 early stage startups to to do
38:39 everything. Um, and that's where it's
38:42 also worth mentioning CDPs, custom data
38:45 platforms, which are sort of the uh
38:48 they're like an all-in-one bundled
38:50 solution where you can track data and
38:52 then you can send data to different
38:53 tools. Um so you can like you can create
38:56 audiences and create your models and
38:58 segments inside a CDP. Of course it has
39:01 limited capabilities. You can't exactly
39:04 do everything you can do in a warehouse
39:05 but it still gives a lot of flexibility
39:07 to marketers and growth professionals to
39:10 to you know work with data without
39:12 relying on on um data teams. So yeah,
39:16 I was trying to take a note at of all
39:20 the tools you mentioned, but there are
39:21 simply so many and I'm wondering so
39:24 let's say I just started a startup.
39:27 I and my co-founder. So I haven't
39:30 started a startup. I'm just like
39:31 hypothetical.
39:31 Hypothetical. Yeah.
39:33 Yes. So I have a co-founder. So there
39:35 are two of us. We just started the
39:36 startup and we understand that uh data
39:40 is important. we want to collect and we
39:42 look at all these tools and there are
39:44 just too many like how do we make a
39:45 decision which tool to choose like u
39:49 I think it's not about
39:51 are they different similar yeah how to
39:53 choose
39:54 yeah I think I think it's first
39:55 important to define what your goals are
39:58 uh and a good way to think about this is
40:00 to like just list down uh you know 10
40:02 question that you want to answer with
40:04 data and then work backwards and and
40:06 figure out the tools uh of course there
40:08 are readymade tools but a lot of
40:10 companies end up um you know fixing
40:13 these problems or implementing these
40:15 solutions without uh buying readym made
40:17 tools by building inhouse tools. So it
40:19 depends u you know what your resources
40:21 are because these tools can also get
40:23 expensive but uh at the very least you
40:26 need you need to start collecting data.
40:28 So you need a tool like a CDI tool like
40:31 segment connections router stack meta
40:34 router I I'll share this whole list
40:37 actually written a lot about this stuff
40:39 so I'll share this list um and once you
40:41 have the data you obviously want to
40:43 analyze it so uh and of course it's
40:45 worth mentioning that a lot of these
40:46 tools do have free tiers free plans so
40:49 you know you can explore different tools
40:51 and see what works for you um but at the
40:54 very least you want to analyze this data
40:57 in a product analytics tool tool um or
40:59 or even like a simple BI tool um or
41:02 both. Actually, it makes sense to you
41:04 know have both depending on um because
41:06 they both sort of serve different
41:08 purposes and you know cater to different
41:10 teams. Um and then of course you you
41:13 want to um have like an email tool where
41:16 you send this data to create
41:18 personalized emails to on create
41:20 onboarding experiences. Um if you have a
41:22 SAS product you want to do some inapp
41:24 onboarding. So you know there are tools
41:26 for that and you can send this data to
41:28 those tools. So there are these four or
41:30 five different tools I so I like to
41:32 mention this. So I like to think of this
41:34 data stack as the modern data stack for
41:37 growth. So uh typically if you hear the
41:40 term modern data stack uh you generally
41:43 hear it in the context of uh analytics.
41:45 Um the modern data stack for analytics
41:48 is like how I would describe it where
41:51 you have uh you have an ELT tool like
41:53 Firef etc where ingesting data from all
41:57 third party tools into a warehouse. Uh
41:59 and then you have a BI tool and you have
42:01 a transformation tool. Um so that's
42:03 typically a monitor stack for analytics.
42:06 Um DBT is worth mentioning here. um you
42:09 know it's growing so fast and you know
42:11 so many companies are adopting DB for
42:13 their transformation needs and modeling
42:15 needs um and then BI tools like looker
42:18 mode etc so so that's like the modern
42:21 data stack for analytics um in terms of
42:24 modern data stack for growth I would say
42:26 you need a data collection tool uh a
42:28 product analytics tool um and then uh a
42:32 warehouse is is almost stable stakes
42:34 like every company should have it um and
42:36 then of course uh tools that that makes
42:39 make data available in your downstream
42:42 SAS tools, you know, sales and marketing
42:44 support tools. Um, and that could be a
42:46 custom data platform. It could be uh if
42:49 you're using tools like segment
42:51 connections and or router stack, they
42:53 can uh do that. They have that
42:54 capability or um if you have if you're
42:57 storing the data in the warehouse then
42:59 you can use a reverse ETL tool. Um and
43:02 each of these categories has obviously
43:04 multiple tools. So you know like a lot
43:06 of them are very similar you know some
43:08 have different capabilities so it's it
43:10 is sort of time consuming to evaluate
43:13 all of these different tools and um you
43:15 know understand the differences and
43:17 that's actually one of the things I'm
43:19 trying to solve u with data academy u
43:21 I'm so launching this thing called
43:23 company profiles where you know you can
43:25 go and u learn about a product um in a
43:29 very simple manner understand uh what
43:31 the product does what the core benefits
43:33 are and uh who the product caters to and
43:36 then get you know answers to questions
43:38 about the product. So um yeah I agree
43:41 like companies spend a lot of time uh
43:43 figuring out the right tools and that is
43:46 a problem that's that that needs to be
43:48 solved. Mhm. And uh myself I'm u I have
43:52 this engineering background. Often I
43:55 look at these tools and think okay why
43:56 they are so expensive I could implement
43:58 something like this. Uh and then of
44:01 course like I know that uh once you
44:03 implement there will be bugs and then
44:04 it's difficult to maintain later. Uh
44:08 yeah uh it's probably I don't know if
44:11 you if you had this in your experience
44:14 you go to a company you say okay this is
44:17 a great tool and then engineer say no no
44:19 no like it's I'm going to implement it
44:22 myself so do you
44:23 I have experienced that a lot
44:27 yeah I would like to say that like like
44:29 one of the things that that that's
44:30 really important to sort of think about
44:32 is that very few people actually like
44:34 using these tools you know for for most
44:36 people it's a headache. It's an
44:38 additional sort of task whether for
44:40 engineers to implement the tool or for
44:42 other business teams to go and use these
44:44 tools. Uh at the end of the day,
44:46 everyone just wants answers to questions
44:49 uh especially when it comes to data or
44:51 they just want data to be available in
44:54 the right format so that they can use it
44:56 um and derive insights from it or act
44:58 upon it. So um yeah like implementing
45:02 new tools is is not easy at all
45:04 especially when it comes to data tools.
45:06 uh there's there's a lot of like
45:07 security uh challenges uh there a lot of
45:10 compliancees issues compliance issues so
45:13 um it is difficult so it's like and
45:15 that's why it's really important to
45:17 understand the problem that the tool
45:19 solves um and then you know if you have
45:21 the resources then you can do like a buy
45:23 versus build analysis you know if you
45:25 build this sort of in-house then uh how
45:29 much you know it'll cost us and whatever
45:31 resources we need to maintain that
45:33 versus uh buying a readym made solution
45:35 or of course open source like it's worth
45:38 mentioning again that a lot of these
45:39 tools uh are open source so rad stack is
45:43 open source uh grouper a reverse utl
45:46 tool is open source a bunch of open
45:49 source bi tools um there there's a
45:52 there's an open source uh product
45:53 analytics tool now called post hog so in
45:56 every category you'll find open source
45:58 tools um if you have again the resources
46:01 of course uh it takes a lot of effort to
46:03 implement an open source tool Just
46:05 because it's open source doesn't mean
46:06 it's like easy to implement but uh if
46:09 you have the resources you can obviously
46:11 you know go that route.
46:13 Okay. And um what kind of roles we need
46:18 to um so we discussed about tools we
46:20 discussed about the flow. So the flow
46:23 from the moment we start capturing the
46:25 data to the moment uh um I think you
46:28 called it data activation. So to the
46:30 moment when data is activated.
46:32 Yeah. Um
46:33 and I heard that uh we need at least to
46:36 have a data like an engineer somebody
46:38 who implements this.
46:40 Um so who else do we need to have in a
46:43 team to implement the whole flow from
46:45 the beginning to the end?
46:47 Yeah, I would say like um typically you
46:50 know for early stage startups you may
46:51 not have a dedicated data engineer. So
46:54 uh you know different like any engineer
46:56 a backend engineer could could help you
46:58 with that stuff u or even a front-end
47:00 engineer could help you with a bunch of
47:02 that stuff uh but eventually you'd need
47:04 a data engineer to manage all of these
47:06 different data pipelines and you know
47:08 it's not just about implementing the
47:10 tool once right you you have to u
47:12 maintain it you have to make sure that
47:14 you know everything is is working
47:15 properly and then of course teams have
47:17 have continuous requests for new new new
47:20 events to track you know you want to add
47:22 more data you want to collect own data.
47:24 So, um yeah, at the very least you'd
47:26 need uh a data engineer and then um if
47:29 you if you have uh if you're using a BI
47:32 tool and you're if you're implementing a
47:34 warehouse, then it makes sense to have a
47:36 data analyst who will be uh you know
47:38 analyzing the data and like you know
47:40 making the data u available in the BI
47:42 tools. So, uh at the very least you need
47:45 those two. I've seen companies hire u
47:47 you know one data person who who does
47:49 pretty much all of this stuff. Uh and
47:53 now now like there's there's obviously
47:54 analytics engineering which is uh a more
47:57 specialized role uh which sort of sits
48:00 in between data engineering and data
48:03 data uh analysis and they they
48:05 specifically work on on tools like DBT
48:08 and they they you know build data
48:10 models. Um so again depending on the
48:12 resources you eventually need you know
48:15 uh all of these people. Um there are
48:17 companies that are hiring data ops
48:19 people who who basically just you know
48:21 make sure uh that all of these different
48:23 tools are working. Um you know all of
48:26 these different teams have access to to
48:28 the tools that they need and uh to the
48:30 resources that they need. Um there are
48:32 companies that that are creating product
48:35 ops teams. So companies that don't have
48:37 sort of dedicated data teams they're
48:39 calling uh this team called product ops.
48:41 and prototyps uh often does uh a lot of
48:44 the work that uh data teams do. So you
48:47 know they they take care of all the
48:49 tools, they take care of your ETL
48:51 pipelines, they take care of your
48:53 warehouse, again you have an analyst, an
48:55 engineer um and and someone who
48:57 understands the product really well. Um
49:00 so um yeah, it depends on like it
49:02 doesn't matter what you call it, but uh
49:04 depending on your resources, you sort of
49:07 decide how many people you'd want um in
49:09 a team like that. Um it definitely makes
49:12 sense to you know empower product teams
49:14 and growth teams to to understand all of
49:17 this stuff. So then they can sort of
49:19 support these teams uh or like you know
49:21 they can support these teams by by uh
49:24 taking up a lot of the work and and not
49:26 like adding more work for these for for
49:29 data people. The one of the typical
49:31 challenges is that data people are
49:33 overwhelmed with requests you know from
49:35 different teams where different teams
49:37 have requests to track new data or you
49:39 know like make data available in
49:41 different tools or create dashboards. uh
49:44 if you enable um different teams to to
49:47 do a lot of that work themselves um then
49:50 then obviously you can make your data
49:51 people more efficient and that's what
49:54 that's the whole sort of conversation
49:56 around um data democrization where
49:59 you're you're not just making data
50:01 accessible for people but you're
50:03 enabling them to to sort of um work with
50:06 data and like um uh you're you're
50:09 implementing self-s serve analytics
50:11 tools so that you know people can go and
50:13 and like derive insights from data
50:15 themselves. Um you're you're investing
50:17 in in upskilling people uh maybe um
50:21 having people learn some basic SQL so
50:23 that they can run very simple queries um
50:27 you know so that they don't have to rely
50:29 on on their on on data people to to
50:32 create like for every query that they
50:34 that they want to run or at least they
50:37 can like take a SQL query and put it in
50:39 the right place and run it and then
50:41 understand it. So um again like these
50:44 things are are becoming more and more
50:46 common and it just makes sense for like
50:48 pretty much every sort of team to to
50:51 learn these skills and become data
50:53 literate and I strongly believe that uh
50:56 one doesn't need to have like an
50:58 engineering background or or even a
51:00 technical any sort of a technical
51:02 background uh to to work with data.
51:06 Mhm. So yeah, quite a few uh quite a few
51:09 roles we need to have. Uh but I also
51:12 like uh because not every company needs
51:15 all these people. So for a smaller uh
51:18 for just early stage startup maybe they
51:21 just need somebody like u an analytics
51:24 engineer maybe who can do both analytics
51:26 and uh some data engineering right
51:29 and then as a team grow like maybe we
51:31 can have uh they can have data engineer
51:34 then maybe a data ops team who can
51:36 support uh all the tools and then they
51:40 also talked about data democratization
51:43 and as I understood you so this
51:47 Uh this is about enabling
51:50 people in in the company like analysts
51:53 and others
51:54 uh who need access to the data to
51:56 actually go and access the data
51:58 themselves, go and an analyze data
52:00 themselves, go and implement some things
52:02 on top of data themselves, right? Is
52:04 there more to that? Like what is it?
52:07 Yeah, I think uh data literacy is a big
52:09 part of it. uh you cannot just
52:11 democratize data just by making data
52:13 available or just by giving people
52:15 access to to to different tools. Um so
52:19 you know investing in in data literacy
52:21 uh having people understand uh from from
52:24 like less technical teams or business
52:25 teams you know uh how data works making
52:28 investing in documentation maybe
52:30 investing in a in a data cataloging uh
52:32 tool or data documentation tool whatever
52:35 you want to call it the tools like atlin
52:38 bunch of others that that are working on
52:40 this sort of solving this problem. Um so
52:43 making data available, investing on on
52:46 uh on data literacy within an
52:47 organization and then making data
52:49 available in the right tools um where
52:52 people can actually use that data um and
52:55 not just look at dashboards. Um and then
52:58 of course like upskilling them so that
53:00 they can like uh efficiently use product
53:03 analytics tools to to you know self-s
53:05 serve their their analytics needs or
53:08 even um like I said learn some SQL to go
53:11 and you know use a BI tool. Um so yeah I
53:14 think I think it's it's it's about uh to
53:17 sum it up I would say it's investing in
53:19 data literacy and making data available
53:22 making clean accurate data available u
53:25 in the different tools across an
53:27 organization um yeah
53:30 and uh also documented right available
53:32 and yeah I think that's
53:34 yeah I mean if you don't document it
53:35 especially in a remote world like uh
53:37 it's it's crazy u like it's it's one of
53:40 the most important things people need to
53:42 companies need to think about um and
53:45 it's one thing that very few people like
53:46 to do.
53:48 Yeah. About that uh how to actually
53:51 motivate people to write data
53:53 documentation because I I know it's
53:55 difficult like as a data scientist I am
53:58 uh uh the one who constantly produced
54:02 new data for others to consume.
54:04 But this step of documenting this data
54:07 is somewhat annoying. So how do you
54:09 convince people like me and others to
54:11 actually go and document this data?
54:14 Yeah, I think it it it works when you
54:16 start small. Uh and you you start early
54:19 like the the earlier that you start the
54:21 easier it is going to be. If you if you
54:23 keep sort of delaying it, it becomes
54:25 difficult. Um and then again like I
54:28 strongly believe that if there's a tool
54:30 that that can solve your problem, you
54:31 should explore that tool and adopt that
54:34 tool. So uh tools like ATLN which are
54:37 sort of these new new age data
54:39 documentation data discovery tools
54:41 they're they're they basically integrate
54:43 with all your different data sources
54:45 with your warehouse with the BI tools
54:47 with different tools and they they
54:48 actually automate a lot of this
54:49 documentation process and and data
54:51 exploration. So uh if you have a lot of
54:55 different data sources and you you have
54:56 a lot of you know u you have a lot of
54:59 data in different places and you don't
55:01 have uh like a way to to efficiently
55:04 document it then then it's worth
55:05 exploring these tools but obviously like
55:08 before you invest in a in a data
55:10 documentation cataloging tool you need
55:12 to have uh the right data infrastructure
55:14 in place. It obviously comes after you
55:17 know once you have data collection
55:18 warehousing um analysis activation all
55:21 of that you know in place that's when
55:23 you invest in these tools. So I think if
55:27 you're starting today then it should be
55:29 like table stakes that everything that
55:31 is being tracked should be documented um
55:34 and you know everywhere the data is
55:35 being used should be documented and uh
55:38 you know like that that's that's how
55:39 you'd go about it. If you don't start
55:41 early then then it's just going to be a
55:43 mess later on. Mhm. Okay. So, it's more
55:46 about the culture and mindset, right?
55:48 So, you just uh
55:49 Yeah.
55:49 You just say, "Okay, we need it. Uh we
55:52 start early and for all the data we
55:54 produce, we must have documentation
55:56 because if we don't, then it becomes a
55:58 mess, right?"
55:59 Yeah. Yeah. It's really important to
56:01 start early. I think kind like you
56:02 mentioned, it's definitely a culture
56:04 thing, you know. Um so, yeah. Thanks for
56:06 mentioning that.
56:07 Okay. One thing I actually wanted to ask
56:10 you at the very beginning but uh we
56:13 didn't uh cover this. So there is a
56:15 thing also called productled right
56:18 and I wanted to ask you what is
56:20 productled and what is the difference
56:23 between uh being a productled and being
56:25 a data le if there is any
56:27 yeah yeah great question I think uh
56:30 being being productled requires you to
56:32 be data uh because the whole idea of
56:35 being productled is is uh enabling your
56:38 product to drive growth or using your
56:40 product to drive growth rather than uh
56:43 investing in sales although You know, of
56:45 course, there, you know, productled and
56:47 sales can can definitely coexist, but um
56:50 one of the principles of product is
56:52 that, you know, users or prospects or uh
56:56 customers can should be able to try your
56:58 product before they buy the product,
57:00 right? So, um you want to have have like
57:03 a free trial or a free plan. Um, and
57:06 then people should be able to use the
57:07 product and derive value from it before
57:11 they they're asked to buy it before a
57:13 salesperson. And this takes us back to
57:15 to to the earlier conversation where I
57:17 mentioned that, you know, once the
57:18 saleserson sees that prospect uh has
57:21 actually you know used the product and
57:23 derived some value or reached aha moment
57:25 of the product. often we refer to it to
57:28 it as uh the activation event where
57:31 again in a project management tool it
57:32 could be creating project and adding uh
57:35 one user and creating three tasks you
57:37 know and that's when you feel like you
57:38 know the user has derived some value
57:40 from the product um so that is being
57:43 productled like um and typically
57:45 productled applies to organizations not
57:47 not individuals so typically you're a
57:49 productled company where you invest in
57:51 these uh sort of productled uh efforts
57:54 and a productled motion
57:56 and a self-s serve onboarding
57:57 experience. And to create that self-s
58:00 serve onboarding experience, you need
58:02 data. If you don't have data, then
58:03 you're not able to sort of enable
58:06 prospects to have that personalized
58:08 experience when they're starting uh to
58:10 use your product. A common example is uh
58:12 you know uh in inapp walkthroughs or
58:15 onboarding walkthroughs that you
58:17 typically see when you start using a new
58:19 product. uh you can actually personalize
58:21 it, personalize it a lot uh based on you
58:25 know the the role of the user or the
58:27 industry of the user and then keep
58:29 personalizing it based on the features
58:31 they're using in the product. Um but
58:33 only if you are data led if you have the
58:35 data and you're using data to to build
58:38 those onboarding experiences or
58:40 triggering emails. Emails is a great
58:42 example. Um a lot of companies you might
58:44 have received an email from a company
58:46 saying that hey uh you should try using
58:49 this feature uh after you've already
58:51 used that feature. That's very common
58:53 right? Uh and and that's that's like you
58:55 know you it's it's very it's a very bad
58:58 experience because you you've actually
59:00 opened that email um and someone who's
59:02 who's created that campaign they'll be
59:04 very happy because you know they see a
59:06 good open rate but actually it's it's
59:08 annoyed you because you're like this
59:10 their emails are useless next time I'm
59:12 not going to open their emails because
59:13 they're telling me to do things I've
59:14 already done right u but if you had data
59:17 if you're data led you not do that you'd
59:19 make sure that if someone has used a
59:21 feature they will not be asked to use
59:23 that feature again.
59:26 So if I can try if I can attempt to
59:29 summarize what you said. So being a
59:31 product it first of all applies to a
59:33 company not to an individual. It's about
59:36 uh taking feedback uh from users and
59:40 then being led by this feedback being
59:43 led by what users want
59:45 and to be able to do this you cannot
59:47 call every user and ask hey like what
59:50 should we do right so you need to
59:51 actually track the data you need to have
59:53 this data to make a
59:56 how yeah
59:57 if I may say datadriven decision right
1:00:00 uh yeah
1:00:01 like a decision like baked by data like
1:00:04 when or data informed data informed
1:00:07 decisions.
1:00:08 Uh and feedback is definitely an
1:00:10 important part of it like you know
1:00:11 gathering feedback while people are
1:00:13 using the product uh you know running
1:00:15 micro surveys in the product or even uh
1:00:18 gathering like u qualitative data by
1:00:21 looking at heat maps and session
1:00:22 recordings like all of that stuff sort
1:00:24 of drives towards um a productled uh
1:00:27 approach.
1:00:29 Okay, thank you. So we should be
1:00:30 wrapping up and they wanted to ask you
1:00:32 if you want to say any like any last
1:00:37 comments like anything you want to
1:00:39 mention.
1:00:40 Well, I would say just just reach out to
1:00:42 me uh in the data slack community if you
1:00:45 have any questions. I'd love to answer
1:00:46 your questions and uh you can check out
1:00:48 datal.academy and uh you can sign up to
1:00:51 uh my newsletter. Uh it's not a weekly
1:00:54 newsletter. I sent out almost every two
1:00:57 weeks where I share all of these
1:00:58 different lessons. Um, and you can
1:01:00 actually check out the past issues on
1:01:02 the website where a lot of the stuff
1:01:03 that I talked about is already sort of
1:01:05 uh written. So that'll be helpful for
1:01:07 you. So yeah, and thanks again for for
1:01:09 joining and and listening uh to us.
1:01:12 Yes. And you uh I will add to what you
1:01:15 just said that uh you should also go and
1:01:18 check podcast, right? So how many
1:01:21 episodes how many episodes do you have
1:01:23 already? We we have uh seven uh episodes
1:01:26 published already. Seven episodes
1:01:29 uh published
1:01:30 and yeah if someone is is is interested
1:01:32 in in like uh talking to to me about
1:01:35 especially if you're from a data company
1:01:37 um I'd love to you know chat with you
1:01:39 and if you want to be on the podcast
1:01:41 feel free to reach out to me.
1:01:43 Seven episodes are live here.
1:01:45 So live it means that you recorded some
1:01:47 which are not published yet right?
1:01:48 Yes. Okay.
1:01:49 Can you tell how many there are there
1:01:51 already?
1:01:53 Well, we have three three more already
1:01:55 in the queue which are ready to go.
1:01:57 Yeah. Okay. Stay tuned. Right.
1:01:59 Yeah. Absolutely. Thank you. Thanks
1:02:01 again for having me. It was great chat.
1:02:03 Yeah, it was it was great indeed. A lot
1:02:05 of information. I took so many notes and
1:02:07 uh like with these tools uh yeah I'll
1:02:10 reach out to you later after after today
1:02:13 to to get the links from you and then
1:02:15 I'll put them in the in the description.
1:02:17 And yeah, thanks everyone for joining us
1:02:20 today for listening.
1:02:22 Uh, hope you enjoyed it. We didn't get
1:02:24 any questions, but uh, yeah, there was a
1:02:27 lot of questions from me. Uh, so I kept
1:02:30 you entertained.
1:02:32 Yeah.
1:02:32 No, it was great. I always like chatting
1:02:35 about this stuff, so thanks again. And,
1:02:37 uh, yeah, hopefully we'll keep the
1:02:38 conversation going um, on Slack.
1:02:41 Definitely. Okay, thanks again. And uh